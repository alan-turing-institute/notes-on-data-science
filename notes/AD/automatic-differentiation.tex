\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{beton}
\usepackage{eulervm}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{microtype}
\usepackage{ellipsis}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{color}
%%
\usepackage{minted}
%%
\usepackage[hidelinks]{hyperref}
% \usepackage{siunitx}
%
%\usepackage[medium, compact]{titlesec}
%\usepackage[inline]{asymptote}
%\usepackage{tikz-cd}
\DeclareFontSeriesDefault[rm]{bf}{sbc}
% \usepackage{amssymb}
%% Turing grid is 21 columns (of 1cm if we are using A4)
%% Usually 4 "big columns", each of 4 text cols plus 1 gutter col;
%% plus an additional gutter on the left.
\usepackage[top=2.82cm, bottom=2.82cm, left=1cm, textwidth=11cm, marginparsep=1cm, marginparwidth=7cm]{geometry}
\usepackage[Ragged, size=footnote, shape=up, alerton]{sidenotesplus}
\usepackage[dvipsnames]{xcolor}
%% We used to use a two-column layout
% \setlength{\columnsep}{1cm}
\title{Automatic differentiation}
\author{James Geddes}
\date{\today}
%%
\newcommand{\eg}{\emph{Example:}}
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\isdef}{\mathrel{\stackrel{\text{def}}{=}}}
\newcommand{\set}[1]{\boldmath{#1}}
\newcommand{\setR}{\set{R}}
\hyphenation{anti-sym-met-ric}
%%
\newcommand{\cd}[1]{\mintinline[escapeinside=||,mathescape=true]{python}{#1}}
\newcommand{\tok}[1]{\framebox{\raisebox{0pt}[1.3ex][0.3ex]{#1}}}
%%
% \usepackage[backend=biber]{biblatex}
% \addbibresource{../cyberdefence.bib}
% \DefineBibliographyStrings{english}{
%   andothers = {\mkbibemph{et\addabbrvspace{al}\adddot}}
% }
%%
\begin{document}
\maketitle

\section{Introduction}%
\label{sec:introduction}

\begin{marginfigure}
  \caption{A plot of $\exp(-x^2/2)$. Our goal is to obtain the
    deriviative of this function.\label{fig:gaussian-plot}}
  \centering
  \includegraphics[width=\marginparwidth]{./images/gaussian-plot.pdf}
\end{marginfigure}
Automatic differentiation is the process of programmatically
transforming a program that computes some function into a program that
computes the derivative of that function. It is distinguished from
numerical differentiation in that the resulting program computes the
exact derivative, not an approximation to it. (Except for the
approximation introduced by the use of floating point numbers.) It is,
perhaps, a little like symbolic differentiation, although what one is
differentiating is a program, not a mathematical
expression.\footnote{I do not follow the arguments about why automatic
  differentiation is not the same as symbolic differentiation and,
  indeed, there seems to be disagreement about what those arguments
  are. At least one researcher, Conal Elliot, believes they are the
  same (see, e.g., his talk at YOW! 2017, ``Teaching new tricks to old
  programs'').}

\section{Part  I}

\subsection{Representing programs}

Here is an example program.\footnote{This program is written in a
  language called Rhombus, a language that is almost, but not quite,
  entirely unlike Python.} Given a real-valued (well, floating-point--valued)
argument, it computes a real-valued output, a plot of which is shown
in figure~\ref{fig:gaussian-plot}.
\begin{minted}[xleftmargin=\parindent]{python}
fun g(x):
  exp(-x*x/2)
\end{minted}
This program computes the function $e^{-x^2/2}$. We wish to obtain its
derivative with respect to~$x$. We could of course
differentiate $e^{-x^2/2}$ and manually code the result as a
program. However, the task of automatic differentiation is to start
with the \emph{program}.
\begin{marginfigure}
  \caption{Examples of Rhombus syntax.}
  \footnotesize
  Expressions follow a familiar syntax:
\begin{minted}{python}
> 1 + 2 * 3
7
\end{minted}
  Definitions of variables use \cd{def} and are immutable by default:
\begin{minted}{python}
> def x = 1 + 2 * 3
\end{minted}
  Functions are defined by \cd{fun} and may be anonymous (like
  ``lambdas''):
\begin{minted}{python}
> fun add1(x): x + 1
> add1(3)
4
> (fun (x): x + 1)(3)
4
\end{minted}
  Lists (zero-indexed) and maps (dictionaries) look like Python:
\begin{minted}{python}
> def xs = [1, 2, 3]
> xs[1]
2
> def ms = {"a": 1, "b": 2}
> ms["b"]
2
\end{minted}
  Classes are defined a bit like in Python but with less mucking about
  with \cd{__init__}:
\begin{minted}{python}
> class Lit(val)
> def literal_two = Lit(2)
> literal_two.val
2
\end{minted}
\end{marginfigure}

If we are to write a program which takes, as input, a \emph{program},
we had better be able to represent a program as data. Consider the
expression in the body of the procedure definition, namely
\cd{exp(-x*x/2)}. What is a good representation of this
expression, suitable for programmatic transformation? 

There seem to be several different kinds of object in this expression:
among them are numbers, variables, operators, and functions. However,
there is one important abstraction that we should make right away, and
that is to observe that operators are really functions in
disguise. Instead of writing, say, \cd{x/2}, we could have written
\cd{div(x,2)} for some suitably defined function, \cd{div}. Operators
are a syntactic convenience, used partly to make expressions in code
look more like their conventional mathematical form, but semantically
they are functions.\footnote{Usually this simplification happens in a
  way that is not accessible to the programmer but in Python the
  functions corresponding to operators \emph{are} visible: they are
  things like ``\cd{__add__}''.}

Here, then, is a possible definition of expressions, like this one. An
\emph{expression} is either:
\begin{enumerate}
\item A \emph{literal}, such as \cd{2}, \cd{3.142}, or \cd{0} (we
  shall only deal with literal numbers);
\item A \emph{variable}, such as \cd{x}, \cd{y}, or \cd{z}; or
\item A \emph{procedure application}, such as \cd{div(x,2)}, where the
  terms in parentheses are themselves expressions.
\end{enumerate}
% Here's how one parses \cd{exp(-x*x/2)} according to this
% definition. First, we write the operators as functions to obtain
% \begin{minted}{python}
% \cd{exp(neg(div(mul(x,x),2)))}
% \end{minted}
% Notice that this is a much more uniform notation! Then:
% \begin{itemize}
% \item \cd{x} is a variable, hence an expression.
% \item Since \cd{x} is an expression, both arguments of \cd{mul(x,x)}
%   are expressions, so \cd{mul(x,x)} is a procedure application, hence
%   an expression.
% \item \cd{2} is a literal, hence an expression.
% \item So both arguments of \cd{div} in \cd{div(mul(x,x),2)} are
%   expressions; so the whole term is a procedure application, hence an
%   expression.
% \item So \cd{neg(div(mul(x,x),2))} is an expression.
% \item So \cd{exp(neg(div(mul(x,x),2)))} is an expression.
% \end{itemize}
\begin{marginfigure}
  \caption{\cd{Expr}: Rhombus class definitions for the construction
    of an abstract syntax tree. These definitions introduce classes
    for literals, variables, and procedure applications, all of which
    are subtypes of expression (indicated by the option ``\cd{extends
      Expr}''). The operator ``\cd{::}'' introduces an optional type
    annotation.\label{fig:class-defs}}\footnotesize
\begin{minted}{python}
class Expr():
  nonfinal

class Lit(val :: Number):
  extends Expr

class Var(name :: String):
  extends Expr

class App(name :: String,
          args :: List.of(Expr)):
  extends Expr
\end{minted}
\end{marginfigure}
A suitable set of class definitions that captures this definition of
an expression is shown in figure~\ref{fig:class-defs}. The base class
is \cd{Expr}, with subclasses \cd{Lit}, \cd{Var}, and \cd{App} for the
three kinds of expression. With these class definitions, the
expression in the body of \cd{g} is represented by the value:
\begin{minted}{python}
def gaussian:
  App("exp",
      [App("neg",
           [App("div",
                [App("mul", [Var("x"), Var("x")]),
                 Lit(2)])
            ])
       ])
\end{minted}
Figure~\ref{fig:expression-tree-gaussian} shows a slightly different
view of the same data structure, which is perhaps slightly more
readable than the definition just above. Because the data structure
represents an abstraction over the surface syntax of the programming
language, it is known as an \emph{abstract syntax tree}, or~AST.
 \begin{marginfigure}
  \caption{A tree, representing the expression denoted by
    ``\cd{gaussian}'' in the main text. Leaf nodes are simply
    labelled with their values; procedure application nodes are
    labelled with the procedure.\label{fig:expression-tree-gaussian}}
  \centering
  \includegraphics{./images/gaussian-tree.pdf}
\end{marginfigure}

The AST is more convenient than the surface syntax for the purpose of
programmatic transformation: that is why the first step of a compiler
or interpreter is to convert the surface syntax to an AST.\@ However,
it is also true that the AST is not very convenient to read or write
directly. One might hope for a serialisable format that is both easy
for the computer to parse \emph{and} easy for people to read and
write. We will come back to this point later.

It is worth noticing what is missing from the above. An \cd{Expr} is a
data structure for expressions but not for general programs. We don't
have a way to express bindings, for example, nor can we express
function definitions.

However, we can certainly represent \emph{some} interesting
mathematical functions as a data structure. Before trying to
differentiate these expressions we should probably try \emph{evaluate}
them. That is, we should write a program which takes, as input, an
object of type \cd{Expr} and produces a value.

\subsection{Evaluating programs}

\begin{marginfigure}<0pt>
  \caption[Eval procedure]{\cd{eval}: A procedure to evaluate an
    expression,~\cd{e}.\label{fig:eval}}
\footnotesize
\begin{minted}{python}
fun eval(e, env, prims):
  match e
  | Lit(v):         
      v
  | Var(s):         
      env[s]
  | App(p, args):
      def arg_vals:
        args.map(eval(_, env, prims))
      prims[p](& arg_vals)
\end{minted}
\end{marginfigure}
Here are the general rules for evaluating \cd{Expr}s. In these rules,
$v$ is a value, $s$ is a string representing a variable, and $p$ is
the name of a primitive (i.e., built in) function.
\begin{enumerate}
\item The value of \cd{Lit(|$v$|)} is just the value~$v$;
\item To evaluate \cd{Var(|$s$|)}, look up the value of the
  variable~$s$;\label{item:eval-var}
\item To evaluate \cd{App(|$p$|, [|$e_1, e_2, \dotsc$|])} first
  evaluate the expressions $e_1$, $e_2$, \dots, then look up $p$ in
  the set of primitive functions, then apply that primitive function
  to the values of the arguments.\label{item:eval-app}
\end{enumerate}
It is reasonably straightforward to translate these rules into code;
the result is the procedure \cd{eval}, shown in
figure~\ref{fig:eval}. The procedure takes two extra arguments, in
addition to the expression to be evaluated. The first, \cd{env}, is
required because of rule (\ref{item:eval-var}), in which the value of
the variables is to be ``looked up.'' To implement this idea,
\cd{eval} is passed an ``environment,'' \cd{env}, which is a map from
variables to values.\footnote{Up to now, and for the rest of
  Section~\ref{sec:introduction}, we are considering only expressions
  containing a single variable, so carrying this environment around
  may seem excessive, but it will become important later.} For
example, the Rhombus expression \cd{{"x": 3}} is a map, which maps the
variable \cd{"x"} to the value~\cd{3}.

\begin{marginfigure}<0pt>
  \caption{\cd{libMaths}: A small set of primitive procedures, suitable for use as
    the argument \cd{prims} to the \cd{eval} procedure.\label{fig:prims}}
\footnotesize
\begin{minted}{python}
def libMaths:
  {
    // Arithmetic 
   "add": fun(x, y): x + y, 
   "sub": fun(x, y): x - y,
   "neg": fun(x):    -x,
   "mul": fun(x, y): x * y,
   "div": fun(x, y): x / y,
   // Exponential
   "exp": math.exp
  }
\end{minted}
\end{marginfigure}
The third argument, \cd{prims}, is required by rule
(\ref{item:eval-app}). Certain parts of the expression are functions
that are ``built in,'' that is, known to the evaluatory. These are
called ``primitive functions,'' to distinguish them from
progammer-defined functions (which our current syntax does not
support). Figure~\ref{fig:prims} is a (very) small library of
primitive maths functions, enough to be able to evaluate
\cd{gaussian}:
\begin{minted}{python}
> eval(gaussian, {"x": 0}, libMaths)
1
\end{minted}

\subsection{Differentiating programs}

Here is a restatement of our goal, given the context we have developed
so far. We are given a value, \cd{e}, of type \cd{Expr}. We would like
to write a program \cd{deriv :: (Expr, String) -> Expr}, such that
\cd{deriv(e, "x")} is an expression for the derivative of~\cd{e} with
respect to~$x$.

% \begin{marginfigure}
%   \caption{Rules of differentiation.\label{fig:differentiation}}
%   \footnotesize
%   \begin{equation*}
%     \frac{dk}{dx} = 0,
%   \end{equation*}
%   (where $k$ is a constant),
%   \begin{equation*}
%     \frac{dx}{dx} = 1,
%   \end{equation*}
%   and
%   \begin{equation*}
%     \frac{d}{dx}f(u(x), v(x)) = \frac{\partial f}{\partial u} \frac{du}{dx} +
%     \frac{\partial f}{\partial v}\frac{dv}{dx}. 
%   \end{equation*}
% \end{marginfigure}

Suppose \cd{e} is an \cd{Expr}. There are three kinds of expression..

First, \cd{e} may be a literal constant, \cd{Lit(|$v$|)}. Since the
derivative of a constant is zero, the derivative is \cd{Lit(0)}.

Second, \cd{e} may be a variable, \cd{Var(|$s$|)}. If $s$ is the
variable with respect to which the derivative is being taken, then the
result is \cd{Lit(1)}, since $\partial x/\partial x = 1$. Otherwise, the derivative
is \cd{Lit(0)}.

Finally---the difficult case---\cd{e} may be \cd{App(|$p$|, [|$e_1$|,
  |$e_2$|, ...])}. For this case, we turn to the ``chain rule'' of
differentiation. Suppose $f(u(x), v(x), \dots)$ is a function of many
arguments, which are themselves functions of~$x$. The chain rule is:
\begin{equation}\label{eq:chain-rule}
  \frac{d}{dx}f\bigl(u(x), v(x), \dotsc\bigr) =
  \frac{\partial f}{\partial u} \frac{du}{dx} 
  + \frac{\partial f}{\partial v}\frac{dv}{dx}
  + \dotsb. 
\end{equation}

\begin{marginfigure}
  \caption{\cd{deriv}: A procedure to calculate the derivative of an
    expression. \cd{sum_of_exprs} and \cd{mul} are helper functions to
    generate particular expressions.\label{fig:deriv}}
  \footnotesize%
\begin{minted}{python}
fun sum_of_exprs(es):
  match es
  | [e]: e
  | [e, &rest]:
      App("add",
          [e, sum_of_exprs(rest)])

fun mul(e1, e2):
  App("mul", [e1, e2])

fun deriv(e, var, derivs):
  match e
  | Lit(v):
      Lit(0)
  | Var(s):
      if s == var
      | Lit(1)
      | Lit(0)
  | App(p, args):
      let dps = derivs[p](& args)
      let des
        = args.map(deriv(_, var, derivs))
      Function.map(mul, dps, des)
        |> sum_of_exprs 
\end{minted}
\end{marginfigure}
We remark that, although eq.~\eqref{eq:chain-rule} is written with the
usual notation, the usual notation is problematic in several ways. For
one thing, the expression $f(u(x), v(x))$ means ``the value of the
function $f$ given arguments $u(x)$ and $v(x)$,'' which is not a
suitable object of which to take a derivative. What is really meant by
the left-hand side is something like, ``$dg/dx$ where
$g(x) = f(u(x),v(x))$.''

On the right-hand side, we have other problems. The expression
$\partial f/\partial u$ is peculiar since $u$ is a function, and we don't mean to
take the derivative of $f$ with respect to a function. Instead, what
is meant is ``the partial derivative of $f$ with respect to its first
argument, evaluated at the point where its arguments are $u(x)$
and~$v(x)$.''

At any rate, eq.~\ref{eq:chain-rule} tells us that \cd{deriv(e, "x")}
is a sum of terms (those on the right-hand side of
eq.~\eqref{eq:chain-rule}), each of which is a product:
\begin{minted}[escapeinside=||,mathescape=true]{python}
App("mul", [|$p^{(i)}$|, deriv(|$e_i$|, "x")])
\end{minted}

\begin{marginfigure}<0pt>
  \caption{\cd{libDeriv}: A library of derivatives of primitive
    procedures. The functions in this library should be called with
    the arguments to the term being differentiated; the result is a
    list of the derivatives with respect to each argument.\label{fig:deriv-library}}
  \footnotesize
\begin{minted}{python}
def libDeriv:
  {
    "add": fun(u, v): [Lit(1), Lit(1)],
    "sub": fun(u, v): [Lit(1), Lit(-1)],
    "neg": fun(u): [Lit(-1)],
    "mul": fun(u, v): [v, u],
    "div": 
      fun(u, v):
        [App("div", [Lit(1), v]),
         App("neg",
             [App("div",
                  [u, App("mul",
                          [v, v])])])],
    "exp": fun(u): [App("exp", [u])]
  }
\end{minted}
\end{marginfigure}
In this expression, $p^{(i)}$ is an AST representing the derivative of
$p$ with respect to its $i$th argument, evaluated at
$(e_1, e_2, \dotsc)$. To compute $p^{(i)}$ we consult a library of
derivatives of primitive procedures, a small part of which is shown in
figure~\ref{fig:deriv-library}.

Here is the derivative of \cd{gaussian}:
\begin{minted}{python}
> def dgaussian = deriv(gaussian, "x", libDeriv)
> eval(dgaussian, {"x': 0}, libMaths)
0
\end{minted}
A plot of \cd{dgaussian} is shown in figure~\ref{fig:dgaussian-plot}.
The plot was obtained by creating a ``normal'' function:
\begin{minted}{python}
fun dg(x):
  eval(deriv(gaussian, "x", libDeriv), {"x": x}, libMaths)
\end{minted}
and then passing that function to a standard plotting library. A nice
feature of our work so far is that the output of \cd{deriv} is also
an expression and so \cd{deriv} can be applied to \emph{that} to
obtain the second derivative.

\subsection{The end of the story?}
\begin{marginfigure}<0pt>
  \caption{A plot of the derivative and second derivative of the
    gaussian.\label{fig:dgaussian-plot}}
  \centering
  \includegraphics[width=\marginparwidth]{./images/dgaussian-plot.pdf}
\end{marginfigure}
  
It would seem that it merely remains to enlarge the library of
primitive functions, along with their derivatives, until it captures
all the expressions one might wish to use. This enlargement introduces
no new ideas and so on the face of it the subject is now complete.

However, there are several gaps in this program. For one thing,
writing expressions is extremely inconvenient! In some sense, we are
manually doing the work of a compiler. Of course, parsing is well
understood so it should be straightforward to create a parser for a
little ``expression language'' and have it produce the \cd{Expr}
value.

Still, there is a subtle point here, which is that somehow there are
now \emph{two} languages to think about. One is the ``host''
language---Rhombus in the examples above but perhaps Python or Julia in
practice---in which one normally does one's work. But now there is also
a little ``guest'' language, the ``expression language'' in which we
write the functions that we wish to differentiate. Even if there were
a parser for a nicer version of this language, it would still be a
different language.

And that raises some obvious questions: what is the definition of this
``guest'' language? What features should it have? Do we have to import
wholesale the computer science of compilers and interpreters?  There
would be less for the programmer to worry about, perhaps, if the guest
language were the same as the host language: is that possible?
\begin{figure*}[h]
  \caption{The AST for \cd{dgaussian}.\label{fig:dgaussian-tree}}
  \centering
  \includegraphics[width=\textwidth]{./images/dgaussian-tree.pdf}
\end{figure*}

A second observation is that we have implemented \cd{eval()} as an
interpreter on \emph{top} of the host language. Almost certainly, our
implementation is not performant, being at least one layer away from a
compiled language, and possibly two.

Another problem is apparent on looking at
figure~\ref{fig:dgaussian-tree}. This is the AST of the result of
differentiating the original expression. It has 32 nodes compared to
the original~7, many of them unnecessary. (And the second derivative
has 193 nodes.) There are some immediate optimisations we might try,
such as replacing \cd{App("mul", 1, |$v$|)} by $v$, and it would be
straightforward to implement those.

However, there are other inefficiences that are harder to remove. Some
of the subtrees occur more than once: really, these subtrees should be
shared, so that they are not computed more than once. Along similar
lines, this tree contains, as a subtree, the \emph{entirety} of the
original expression. In the usual case where we wish to compute, for
some function, both the value of the function and its derivative,
there will be duplication of the calculation.

But perhaps none of this matters as much as yet another
inefficiency. And that is that, typically, we do not want the
derivative only with respect to a \emph{single} variable. Typical
functions---typical in machine learning, anyway---depend on \emph{many}
variables, and we want the derivative with respect to all of them. In
applications, ``many'' might mean ``billions.'' (They are the
parameters of the model.) The \cd{deriv()} procedure already allows
differentiation with respect to multiple variables but it will produce
a new expression for each one. Crucially, nearly all of those trees
will have shared subtrees and will be recomputed as many times as
there are variables.

The rest of the story will be about what we do about these gaps in the
program.

\section{The rest of the story (tbd)}

\begin{enumerate}
\item Sharing, let-bindings, maybe ANF. (Simple JAX example.)
\item Applications: Logistic regression, Gaussian mixture models
\item ``Duals''
\item Vectors! Linear maps! Differential geometry!
\item What the ML people do 
\item More general programs
\item Conal Elliot's stuff
\item \dots
\end{enumerate}


\section{Expression sharing}

We have so far constructed a very simple language, without even a
surface syntax. All we have is an abstract syntax tree, described by
its representation as a data structure in Rhombus.

Here is one way of describing the language as a data structure,
without reference to a particular host language. 
\newcommand{\nonterminal}[1]{\langle\operatorname{\textit{#1}}\rangle}
\newcommand{\lit}{\nonterminal{lit}}
\newcommand{\var}{\nonterminal{var}}
\newcommand{\prim}{\nonterminal{prim}}
\newcommand{\expr}{\nonterminal{expr}}

\begin{equation*}
  \begin{aligned}
%    \lit & ::= 2 \mid 3.1 \mid 0.02 \mid \dotsb \\
%    \var & ::= x \mid y | \dotsb \\
%    \prim & ::= \operatorname{add} \mid \operatorname{mul} \mid \dotsb \\
    \expr  ::= {} & \lit &&& \text{(literal)} \\
             \mid {} & \var  &&& \text{(variable)} \\
             \mid {} & \prim \; \expr \; \dotsc &&& \text{(application)}
  \end{aligned}
\end{equation*}

Figure~\ref{fig:dfgh-tree} illustrates one of the problems described
earlier. The diagram shows a schematic version of the abstract syntax
tree that one would obtain by running \cd{deriv} on the expression
$f(g(h(x)))$. The notation $f'$ means ``the derivative of $f$ with
respect to its argument.'' So this AST illustrates the chain rule:
\begin{marginfigure}
  \caption{AST of the derivative of $f(g(h(x)))$.\label{fig:dfgh-tree}}
  \includegraphics[width=\marginparwidth]{./images/dfgh-tree.pdf}
\end{marginfigure}
\begin{equation*}
  \frac{d}{dx} f(g(h(x))) = f'(g(h(x))) \times g'(h(x)) \times h'(x).
\end{equation*}
(Note that when the chain rule introduces a multiplication, that
multiplication is shown as ``$\times$'' in the diagram, rather than
``\cd{mult}'' for reasons that may, possibly, become clear later.)

The problem is that $h(x)$ is computed twice. It is computed once in
order to compute $g'(h(x))$, and once again to compute
$f'(g(h(x)))$. If one also wanted the value of $f(g(h(x)))$, as is
typical,\footnote{Though, come to think of it, why is it typical?}
then $g(h)$ would also end up being computed twice (and $h(x)$ three
times).






\end{document}

% Local Variables:
% TeX-command-extra-options: "-shell-escape"
% End:
