\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{beton}
\usepackage{eulervm}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{microtype}
\usepackage{ellipsis}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{color}
%%
\usepackage{minted}
%%
\usepackage[hidelinks]{hyperref}
% \usepackage{siunitx}
%
%\usepackage[medium, compact]{titlesec}
%\usepackage[inline]{asymptote}
%\usepackage{tikz-cd}
\DeclareFontSeriesDefault[rm]{bf}{sbc}
% \usepackage{amssymb}
%% Turing grid is 21 columns (of 1cm if we are using A4)
%% Usually 4 "big columns", each of 4 text cols plus 1 gutter col;
%% plus an additional gutter on the left.
\usepackage[top=2.82cm, bottom=2.82cm, left=1cm, textwidth=11cm, marginparsep=1cm, marginparwidth=7cm]{geometry}
\usepackage[Ragged, size=footnote, shape=up]{sidenotesplus}
%% We used to use a two-column layout
% \setlength{\columnsep}{1cm}
\title{Automatic differentiation}
\author{James Geddes}
\date{\today}
%%
\newcommand{\eg}{\emph{Example:}}
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\isdef}{\mathrel{\stackrel{\text{def}}{=}}}
\newcommand{\set}[1]{\boldmath{#1}}
\newcommand{\setR}{\set{R}}
\hyphenation{anti-sym-met-ric}
%%
\newcommand{\cd}[1]{\mintinline[escapeinside=||,mathescape=true]{python}{#1}}
\newcommand{\tok}[1]{\framebox{\raisebox{0pt}[1.3ex][0.3ex]{#1}}}
%%
% \usepackage[backend=biber]{biblatex}
% \addbibresource{../cyberdefence.bib}
% \DefineBibliographyStrings{english}{
%   andothers = {\mkbibemph{et\addabbrvspace{al}\adddot}}
% }
%%
\begin{document}
\maketitle

\section{Introduction}%
\label{sec:introduction}

\begin{marginfigure}
  \caption{A plot of $\exp(-x^2/2)$. Our goal is to obtain the
    deriviative of this function.\label{fig:gaussian-plot}}
  \centering
  \includegraphics[width=\marginparwidth]{images/gaussian-plot.pdf}
\end{marginfigure}
Automatic differentiation is the process of programmatically
transforming a program that computes some function into a program that
computes the derivative of that function. It is distinguished from
numerical differentiation in that the resulting program computes the
exact derivative, not an approximation to it. (Except for the
approximation introduced by the use of floating point numbers.) It is,
perhaps, a little like symbolic differentiation, although what one is
differentiating is a program, not a mathematical
expression.\footnote{I do not follow the arguments about why automatic
  differentiation is not the same as symbolic differentiation and,
  indeed, there seems to be disagreement about what those arguments
  are. At least one researcher, Conal Elliot, believes they are the
  same (see, e.g., his talk at YOW! 2017, ``Teaching new tricks to old
  programs'').}

\section{Part  I}

\subsection{Representing programs}

Here is an example program.\footnote{This program is written in a
  language called Rhombus, a language that is almost, but not quite,
  entirely unlike Python.} Given a real-valued (well, floating-point--valued)
argument, it computes a real-valued output, a plot of which is shown
in figure~\ref{fig:gaussian-plot}.
\begin{minted}[xleftmargin=\parindent]{python}
fun gaussian(x):
  math.exp(-x**2/2)
\end{minted}
This program computes the function $e^{-x^2/2}$. We wish to obtain its
derivative with respect to~$x$. We could of course
differentiate $e^{-x^2/2}$ and manually code the result as a
program. However, the task of automatic differentiation is to start
with the \emph{program}.
\begin{marginfigure}
  \caption{Examples of Rhombus syntax.}
  \footnotesize
  Expressions follow a familiar syntax:
\begin{minted}{python}
> 1 + 2 * 3
7
\end{minted}
  Definitions of variables use \cd{def} and are immutable by default:
\begin{minted}{python}
> def x = 1 + 2 * 3
\end{minted}
  Functions are defined by \cd{fun} and may be anonymous (like
  ``lambdas''):
\begin{minted}{python}
> fun add1(x): x + 1
> add1(3)
4
> (fun (x): x + 1)(3)
4
\end{minted}
  Lists (zero-indexed) and maps (dictionaries) look like Python:
\begin{minted}{python}
> def xs = [1, 2, 3]
> xs[1]
2
> def ms = {"a": 1, "b": 2}
> ms["b"]
2
\end{minted}
  Classes are defined a bit like in Python but with less mucking about
  with \cd{__init__}:
\begin{minted}{python}
> class Lit(val)
> def literal_two = Lit(2)
> literal_two.val
2
\end{minted}
\end{marginfigure}

If we are to write a program which takes, as input, a \emph{program},
we had better be able to represent a program as data. Consider the
expression in the body of the procedure definition, namely
\cd{math.exp(-x**2/2)}. What is a good representation of this
expression, suitable for programmatic transformation? It is the
representation that one obtains after parsing the expression according
to the grammar of the language, producing what is sometimes known as
an \emph{abstract syntax tree}, or AST.

Expressions, like this one, are made up of literal values (like
\cd{2}), variables (like \cd{x}) and procedure applications (like
\cd{exp(...)}). 
\begin{marginfigure}
  \caption{Rhombus class definitions for the construction of an
    abstract syntax tree. These definitions introduce classes for
    literals, variables, and procedure applications, all of which are
    subtypes of expression (indicated by the option ``\cd{extends
      Expr}''). The operator ``\cd{::}'' introduces an optional type
    annotation.\label{fig:class-defs}}\footnotesize
\begin{minted}{python}
class Expr():
  nonfinal

class Lit(val :: Number):
  extends Expr

class Var(name :: String):
  extends Expr

class App(name :: String,
          args :: List.of(Expr)):
  extends Expr
\end{minted}
\end{marginfigure}
Here is a grammar for simple expressions made up of these
components. An \emph{expression} is either:
\begin{enumerate}
\item A literal number, such as \cd{2}, \cd{3.142}, or \cd{0};
\item A variable, such as \cd{x}, \cd{y}, or \cd{z}; or
\item A procedure application, such as \cd{div(x,2)}, where the terms
  in parentheses are themselves expressions.
\end{enumerate}
One might imagine that there are also operators (like
\cd{-}, \cd{**}, and~\cd{/}) but in fact these are not a new thing but
merely a convenient way to write what is effectively a procedure
application. For example, an expression like \cd{2/3} will be
converted into, say, \cd{div(2, 3)} in the abstract syntax
tree.\footnote{Usually this happens in a way that is not accessible to
  the programmer but in Python the functions corresponding to
  operators \emph{are} visible: they are things like
  ``\cd{__add__}''.}

A suitable set of class definitions is shown in
figure~\ref{fig:class-defs}. With these class definitions, literal
\cd{2} is represented by \cd{Lit(2)}; the variable \cd{x} by
\cd{Var("x")}; and the expression in the body of \cd{gaussian} is
represented by
\begin{minted}{python}
def gaussian:
  App("exp",
      [App("neg",
           [App("div",
                [App("mul", [Var("x"), Var("x")]),
                 Lit(2)])
            ])
       ])
\end{minted}
Figure~\ref{fig:expression-tree-gaussian} shows this AST as, well, a
tree, which is perhaps slightly more readable than the data structure.
 \begin{marginfigure}
  \caption{A tree, representing the expression denoted by
    ``\cd{gaussian}'' in the main text. Leaf nodes are simply
    labelled with their values; procedure application nodes are
    labelled with the procedure.\label{fig:expression-tree-gaussian}}
  \centering
  \includegraphics{images/gaussian-tree.pdf}
\end{marginfigure}

The AST is more convenient than the surface syntax for the purpose of
programmatic transformation; that is why the first step of a compiler
or interpreter is to convert the surface syntax to an AST.\@ However,
it is true that the AST is not very convenient to read or write
directly. One might hope for a serialisable format that is both easy
for the computer to parse \emph{and} easy for people to read and
write. We will come back to this point later.

Notice what is missing from the above. An \cd{Expr} is a data
structure for expressions but not for general programs. We don't have
a way to express bindings, for example, nor can we express function
definitions. However, we can certainly represent \emph{some}
interesting mathematical functions as a data structure. Before trying
to differentiate these expressions we should probably try
\emph{evaluate} them. That is, we should write a program which takes,
as input, an object of type \cd{Expr} and produces a value.

\subsection{Evaluating programs}

\begin{marginfigure}
  \caption[Eval procedure]{A procedure to evaluate an expression,~\cd{e}.}
\footnotesize
\begin{minted}{python}
fun eval(e, env, prims):
  match e
  | Lit(v):         
      v
  | Var(s):         
      env[s]
  | App(p, args):
      def arg_vals:
        args.map(eval(_, env, prims))
      prims[p](& arg_vals)
\end{minted}
\end{marginfigure}
Here are the general rules for evaluating \cd{Expr}s. In these rules,
$v$ is a value, $s$ is a string representing a variable, and $p$ is
the name of a primitive (i.e., built in) function.
\begin{enumerate}
\item The value of \cd{Lit(|$v$|)} is just the value~$v$;
\item To evaluate \cd{Var(|$s$|)}, look up the value of the
  variable~$s$;\label{item:eval-var}
\item To evaluate \cd{App(|$p$|, [|$e_1, e_2, \dotsc$|])} first
  evaluate the expressions $e_1$, $e_2$, \dots, then look
  up $p$ in the set of primitive functions, then apply that function to
  the values of the arguments.\label{item:eval-app}
\end{enumerate}

\begin{marginfigure}|2ex|
  \caption{A small set of primitive procedures, suitable for use as
    the argument \cd{prims} to the \cd{eval} procedure.\label{fig:prims}}
\footnotesize
\begin{minted}{python}
def libMaths:
  {
    // Arithmetic 
   "add": fun(x, y): x + y, 
   "sub": fun(x, y): x - y,
   "neg": fun(x):    -x,
   "mul": fun(x, y): x * y,
   "div": fun(x, y): x / y,
   // Exponential
   "exp": math.exp
  }
\end{minted}
\end{marginfigure}Rule (\ref{item:eval-var}) implies that we will need some sort of
environment containing a mapping from variables to values. Up to now,
and for the rest of Section~\ref{sec:introduction}, we are considering
only expressions containing a single variable, so carrying this
environment around may seem excessive, but it will become important
later.

Rule (\ref{item:eval-app}) implies we will need a collection of
primitive procedures already known to our
evaluator. Figure~\ref{fig:prims} is a (very) small library of
primitive maths functions, just enough to be able to evaluate
\cd{gaussian}:
\begin{minted}{python}
> eval(gaussian, {"x": 0}, libMaths)
1
\end{minted}

\subsection{Differentiating programs}

\begin{marginfigure}
  \caption{A library of derivatives of primitive
    procedures. The functions in this library should be called with
    the arguments to the term being differentiated; the result is a
    list of the derivatives with respect to each argument.\label{fig:deriv-library}}
  \footnotesize
\begin{minted}{python}
def libDeriv:
  {
    "add": fun(u, v): [Lit(1), Lit(1)],
    "sub": fun(u, v): [Lit(1), Lit(-1)],
    "neg": fun(u): [Lit(-1)],
    "mul": fun(u, v): [v, u],
    "div": 
      fun(u, v):
        [App("div", [Lit(1), v]),
         App("neg",
             [App("div",
                  [u, App("mul",
                          [v, v])])])],
    "exp": fun(u): [App("exp", [u])]
  }
\end{minted}
\end{marginfigure}
Here is our goal, given the context we have developed so far. We are
given a value of type \cd{Expr}. We would like to write a program
\cd{deriv :: (Expr, String) -> Expr}, such that \cd{deriv(e, "x")} is an expression
for the derivative of~\cd{e} with respect to~$x$.
% \begin{marginfigure}
%   \caption{Rules of differentiation.\label{fig:differentiation}}
%   \footnotesize
%   \begin{equation*}
%     \frac{dk}{dx} = 0,
%   \end{equation*}
%   (where $k$ is a constant),
%   \begin{equation*}
%     \frac{dx}{dx} = 1,
%   \end{equation*}
%   and
%   \begin{equation*}
%     \frac{d}{dx}f(u(x), v(x)) = \frac{\partial f}{\partial u} \frac{du}{dx} +
%     \frac{\partial f}{\partial v}\frac{dv}{dx}. 
%   \end{equation*}
% \end{marginfigure}

Suppose \cd{e} is an \cd{Expr}. There are three possibilities
for~\cd{e}.

First, \cd{e} may be a literal constant, \cd{Lit(|$v$|)}. Since the
derivative of a constant is zero, the derivative is \cd{Lit(0)}.

Second, \cd{e} may be a variable, \cd{Var(|$s$|)}. If $s$ is the
variable with respect to which the derivative is being taken, then the
result is \cd{Lit(1)}, since $\partial x/\partial x = 1$. Otherwise, the derivative
is \cd{Lit(0)}.

Finally---the difficult case---\cd{e} may be \cd{App(|$p$|, [|$e_1$|,
  |$e_2$|, ...])}. For this case, we turn to the ``chain rule'' of
differentiation. Suppose $f(u(x), v(x), \dots)$ is a function of many
arguments, which are themselves functions of~$x$. The chain rule is:
\begin{equation}\label{eq:chain-rule}
  \frac{d}{dx}f\bigl(u(x), v(x), \dotsc\bigr) =
  \frac{\partial f}{\partial u} \frac{du}{dx} 
  + \frac{\partial f}{\partial v}\frac{dv}{dx}
  + \dotsb. 
\end{equation}

\begin{marginfigure}
  \caption{A procedure to calculate the derivative of an
    expression. \cd{sum_of_exprs} and \cd{mul} are helper functions to
    generate particular expressions.\label{fig:deriv}}
  \footnotesize%
\begin{minted}{python}
fun sum_of_exprs(es):
  match es
  | [e]: e
  | [e, &rest]:
      App("add",
          [e, sum_of_exprs(rest)])

fun mul(e1, e2):
  App("mul", [e1, e2])

fun deriv(e, var, derivs):
  match e
  | Lit(v):
      Lit(0)
  | Var(s):
      if s == var
      | Lit(1)
      | Lit(0)
  | App(p, args):
      let dps = derivs[p](& args)
      let des
        = args.map(deriv(_, var, derivs))
      Function.map(mul, dps, des)
        |> sum_of_exprs 
\end{minted}
\end{marginfigure}
We remark that, although eq.~\eqref{eq:chain-rule} is the usual
notation, that notation is problematic in several ways. The expression
$f(u(x), v(x))$ means ``the value of the function $f$ given arguments
$u(x)$ and $v(x)$,'' which is not a suitable object of which to take a
derivative. What is really meant by the left-hand side is something
like, ``$dg/dx$ where $g(x) = f(u(x),v(x))$.''

On the right-hand side, we have other problems. The expression
$\partial f/\partial u$ is peculiar since $u$ is a function, and we don't mean to
take the derivative of $f$ with respect to a function. Instead, what
is meant is ``the partial derivative of $f$ with respect to its first
argument, evaluated at the point where its arguments are $u(x)$
and~$v(x)$.''

At any rate, \cd{deriv(e, "x")} is a sum of the terms (those on the
right-hand side of eq.~\eqref{eq:chain-rule}), each of which is a
product:
\begin{minted}[escapeinside=||,mathescape=true]{python}
App("mul", [|$p^{(i)}$|, deriv(|$e_i$|, "x")])
\end{minted}

In this expression, $p^{(i)}$ is an AST representing the derivative of
$p$ with respect to its $i$th argument, evaluated at
$(e_1, e_2, \dotsc)$. To compute $p^{(i)}$ we consult a library of
derivatives of primitive procedures, a small part of which is shown in
figure~\ref{fig:deriv-library}.

Here is the derivative of \cd{gaussian}:
\begin{minted}{python}
> def dgaussian = deriv(gaussian, "x", libDeriv)
> eval(dgaussian, {"x': 0}, libMaths)
0
\end{minted}
A plot of \cd{dgaussian} is shown in figure~\ref{fig:dgaussian-plot}.
That plot was obtained by creating an ``normal'' function:
\begin{minted}{python}
fun dg(x):
  eval(deriv(gaussian, "x", libDeriv), {"x": x}, libMaths)
\end{minted}
and then passing that function to a standard plotting library.
\begin{marginfigure}|2ex|
  \caption{A plot of \cd{dgaussian}.\label{fig:dgaussian-plot}}
  \centering
  \includegraphics[width=\marginparwidth]{images/dgaussian-plot.pdf}
\end{marginfigure}
  
\subsection{The end of the story?}

It would seem that it merely remains to enlarge the library of
primitive functions, along with their derivatives, until it captures
all the expressions one might wish to use. This enlargement introduces
no new ideas and so on the face of it the subject is now complete.

However, there are several gaps in the program. For one thing, writing
expressions is extremely inconvenient! In some sense, we are manually
doing the work of a compiler. Of course, parsing is well understood so
it should be straightforward to create a parser for the ``expression
language'' and have it produce the \cd{Expr} value.

Still, there is a subtle point here, which is that somehow there are
now \emph{two} languages to think about. One is the ``host''
language---Rhombus in the examples above but perhaps Python or Julia in
practice---in which one normally does one's work. But now there is also
a little ``guest'' language, the ``expression language'' in which we
write the functions that we wish to differentiate. Even if there were
a parser for a nicer version of this language, it would still be a
different language.

And that raises some obvious questions: what is the definition of this
``guest'' language? What features should it have? Do we have to import
wholesale the computer science of compilers and interpreters?  There
would be less for the programmer to worry about, perhaps, if the guest
language were the same as the host language: is that possible?
\begin{figure}[ht]
  \caption{The AST for \cd{dgaussian}.\label{fig:dgaussian-tree}}
  \centering
  \includegraphics[width=0.8\textwidth]{images/dgaussian-tree.pdf}
\end{figure}

A second observation is that we have implemented \cd{eval()} as an
interpreter on \emph{top} of the host language. Almost certainly, our
implementation is not performant, being at least one layer away from a
compiled language, and possibly two.

Another problem is apparent on looking at
figure~\ref{fig:dgaussian-tree}. This is the AST of the result of
differentiating the original expression and has 32 nodes compared to
the original~7. There are some immediate optimisations we might try,
such as replacing \cd{App("mul", 1, |$v$|)} by $v$, and it would be
straightforward to implement those. There are also subtler
inefficiences. Some of the subtrees occur more than once: Really,
these subtrees should be shared, so that they are not computed more
than once. Along similar lines, this tree contains, as a subtree, the
entirety of the original expression. In the usual case where we wish
to compute, for some function, both the value of the function and its
derivative, there will be duplication of the calculation.

But perhaps none of this matters as much as yet another
inefficiency. And that is that, typically, we do not want only the
derivative with respect to a \emph{single} variable, as we have
implemented here, but with respect to \emph{many} variables. In
applications, ``many'' might mean ``billions.'' (They are the
parameters of the model.) The \cd{eval()} procedure already allows
differentiation with respect to any variable;


\section{The rest of the story}

\begin{enumerate}
\item Examples: Logistic regression, Gaussian mixture models (one parameter)
\item Multivariate functions
\item Examples: Logistic regression, Gaussian mixture models (multiparameter)
\item What the ML people do 
\item Differential geometry
\item More general programs
\item Conal Elliot's stuff
\item \dots
\end{enumerate}

\end{document}

Notes on syntax
Notes:
\begin{itemize}
\item \cd{env["x"]} looks up the variable represented by \cd{"x"}
  in the environment.
\item \cd{(prims["neg"])(2)} looks up the function \cd{"neg"} in
  the primitives set and applies the function to the value~2.
\item \cd{eval(_, env, prims)} is a procedure of one argument,
  represented by the placeholder underscore.
\item \cd{args.map(eval(_, env, prims))} maps the function
  \cd{eval(_, env, prims)} over all expressions in \cd{args},
  returning a list. 
\end{itemize}


% Local Variables:
% TeX-command-extra-options: "-shell-escape"
% End:
