\documentclass[10pt, a4paper, twocolumn]{article}
%\usepackage{graphicx}
%\usepackage{textcomp}
%\usepackage{amssymb}
%\usepackage{minted}
\usepackage[T1]{fontenc}
\usepackage{concrete}
\usepackage{euler}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
%\usepackage{fontspec}
\usepackage[margin=0.51in]{geometry}
%\setlength{\parskip}{\smallskipamount}
\usepackage{parskip}
\usepackage{booktabs}
\usepackage[sf, bf, medium, compact]{titlesec}
%%
\usepackage[style=authoryear]{biblatex}
\addbibresource{data.bib}
%%
%%
\author{James Geddes}
\date{March 2022}
\title{Data}
\begin{document}\maketitle
\section{Introduction}
\begin{table*}[!ht]
\centering\small
\begin{tabular}{@{}rllrrrrlr@{}}
  \toprule
 & species & island & bill length & bill depth & flipper length & body mass & sex & year \\ 
 & & & (mm) & (mm) & (mm) & (g) & &  \\ 
  \midrule
  1 & Gentoo & Biscoe & 46.2 & 14.5 & 209 & 4800 & female & 2007 \\ 
  2 & Chinstrap & Dream & 50.9 & 19.1 & 196 & 3550 & male & 2008 \\ 
  3 & Adelie & Dream & 44.1 & 19.7 & 196 & 4400 & male & 2007 \\ 
  4 & Gentoo & Biscoe & 42.6 & 13.7 & 213 & 4950 & female & 2008 \\ 
  5 & Adelie & Biscoe & 40.6 & 18.8 & 193 & 3800 & male & 2008 \\ 
  \bottomrule
\end{tabular}
\caption{Five rows sampled at random from the 344 rows of the `Palmer Penguins'
  dataset (\cite{palmerpenguins}).\label{tbl:penguins}}
\end{table*}

Table~\ref{tbl:penguins} shows a few rows from a publicly-available dataset. It
is presented as a table, perhaps the most common form of `structured' data. But
there is a great deal of information \emph{not} explicitly included in this
table. For example:
\begin{enumerate}
\item{There are, in the world, things called \emph{penguins}.}
\item{The rows of this table describe the properties of an observational unit;
  and that unit is a penguin.}
\item{No individual penguin could occur more than once in any possible version
  of this table.}
\item{Penguins come in distinct \emph{species} and \emph{sexes}.}
\item{\emph{Islands} are also a thing in the world.}
\item{Each penguin stands in a certain spatial relation to one and only one
  island.}
\item{A \emph{flipper length} is a kind of \emph{physical quantity;} specifically, one
  with the dimensions of \emph{length} and the units of \emph{millimetres}.}
 \end{enumerate}
These facts could not be deduced by mere inspection of the data in the
table. The word `penguin' doesn't even appear! Although there are no duplicate
rows in this particular dataset, that doesn't mean that the same penguin could
not appear twice in any version. (The numbers in the far left column are likely
just a way to order the rows rather than a way of individuating penguins.) The
concepts of `species' and `sex' (fundamental characteristics of penguins) are
different from the concept `island' (which would seem to be contingent) but
these two things enter the table in the same way. Neither length nor mass is an
integer, even though the values in the table are all integral.

Some values in the full table are missing. Presumably a missing value indicates
that the corresponding property was not measured or is otherwise unknown, not
that the property has no value. 

All of the above is information beyond that which is available from the table
and yet it is required to actually make use of this table. There's a
tongue-in-cheek observation in the data science community that ``80\,\% of one's
time is spent cleaning the data.'' Given that most of the information
\emph{about} the data is not \emph{in} the data perhaps this observation is
understandable. The point of this note is to try to understand what we can say
about this `missing' information: the data that you need to be able to
understand the data. In other words, what \emph{is} data? In still other words,
what is our \emph{theory} of data?

Perhaps data are \emph{facts}. Then a theory of data would be available if we
had a theory of facts. Well, I'm not sure what facts are. But one thing they
might be is \emph{true} \emph{propositions}. And we do have a theory of
propositions: namely, logic.\footnote{Actually---there are many logics, so perhaps
there are multiple theories of data.}

Two theories of data based on logic are widely used (though not, in my
experience, well-understood by data scientists): the \emph{relational model} and
\emph{ontologies} (specifically, those ontologies described by a `description
logic'). The relational model provides the underpinnings of relational databases
\parencite{codd1970relational} whereas ontologies provide the basis for the
`semantic web' \parencite{DBLP:journals/corr/abs-1201-4089}. But there is
clearly something unsatisfactory about having more than one theory of data!
Presumably neither is sufficient because each is missing something.

The literature on these two theories tends to focus on the computational
complexity of reasoning about the data and not so much on what the data `mean.'
Indeed, both theories are intentionally impoverished compared to (at least some
varieties of) logic in order that they be \emph{decidable}; and ideally,
decidable in something faster than exponential time. In this note, I propose to
completely ignore questions of time and space complexity and mostly ignore
questions of decidability.\footnote{Frankly, you'll be lucky if I worry about
completeness.}

\section{Some terminology in set theory}

Let $X, Y, \dots, Z$ be sets. Then a \emph{relation} over $X, Y, \dots, Z$ is a
subset of $X\times Y\times\dotsm\times Z$.

\emph{Example:} The set $R_\leq \equiv \{(x, y)\in\mathbb{R}\times\mathbb{R} \mid x\leq y\}$ is a
relation. (We could have called the set $\leq$ but writing $(1, 2)\in\leq$ is a bit odd.)

A relation over $X\times X$ is called a \emph{binary relation}. Certain
kinds of binary relation have special names. A binary relation $R$ is said to
be:
\begin{description}
\item[Reflexive] if $(x, x)\in R$ for all $x\in X$;
\item[Symmetric] if $(x, y)\in R$ implies $(y,x)\in R$;
\item[Antisymmetric] if $(x, y)\in R$ and $(y, x)\in R$ imply $x = y$;
\item[Transitive] if $(x, y)\in R$ and $(y, z)\in R$ imply $(x, z) \in R$.
\end{description}

\emph{Example:} The relation $\leq$ is reflexive, antisymmetric, and transitive.

\emph{Example:} A relation over the `unary product' $X$ is just a subset of $X$.

\emph{Example:} A map, $f:X\to Y$ is a relation over $X\times Y$. Specifically, it is
one such that for all $x\in X$ there is some $y\in Y$ for which $(x, y)\in f$.

\emph{Example:} We don't normally talk about the Cartesian product of \emph{no}
sets. However, it is natural\footnote{At least, natural in the category
\textbf{\textsf{Set}}.} to define it to be $\{\emptyset\}$, the set containing a single
element (which we might as well take to be the empty set). Thus there are two
`nullary' relations: one containing no elements; and one containing a single
(empty) element.\footnote{\textcite{darwendate2006ttm} call these ``table dum''
and ``table dee.'' I forget which is which.}

Why are we interested in relations? One good reason is that they allow us to
construct \emph{propositions}: that is, claims that could be true or false. For
example, we might interpret $(x, y)\in R_\leq$ as the proposition ``$x$ is less than
or equal to $y$.'' Thus, $(1, 2)\in R_\leq$ because the claim that $1\leq 2$ is true;
contrariwise, $(3, 2)\notin R_\leq$. When we interpret things this way, we often write
the proposition as, for example, $R_\leq(1, 2)$ (noting that this may be true or
false).


See \textcite{cameron1999sets} for more on set theory (from which some of the
above is taken).


\section{The relational model}

Table~\ref{tbl:penguins} looks rather like the sort of thing one finds in a
relational database so perhaps the relational model is the place to start.

The main feature of tables like this is that they consist of a set of
\emph{tuples} (or `rows'); and the values in corresponding positions in each
tuple (that is, in the same column) have the same `type.' The set of tuples
really is supposed to be a \emph{set}---no two rows can be identical. (In
production systems this rule is often violated for efficiency reasons.)

To try to capture the idea that `values in the same column have the same type,'
let $\mathscr{D}_1, \mathscr{D}_2, \dots, \mathscr{D}_n$ be a finite collection
of sets called \emph{domains}. The point of these domains is to be the
`carriers' of the types of data; that is, each value in a table will be an
element of one of the domains and all values in the same column will be
elements of the same domain.

Already there is trouble: The theory offers very little advice on how these
domains are supposed to be chosen. In practice they are usually taken to be the
`built-in' types of a database system: typically including such types as
`integers between $-2^{31}$ and $2^{31}-1$,' `32-bit floating point numbers,'
`strings of a certain maximum length,' `arbitrary-precision decimals,' and
perhaps even `geospatial coordinates.' But there is a world of difference
between `floating-point number' and `length in millimetres'. Anyway, presumably
we don't really want to think about 32-bit integers (or whatever): we want to
think about `real numbers' or `integers.' \textcite{abiteboul1995foundations}
say (section 3.1):
\begin{quote}
  The entries of tuples are taken from sets of constants, called domains, that
  include, for example, the sets of integers, strings, and Boolean values.
\end{quote}
which sounds reasonably general. But then they also say, a few paragraphs later,
\begin{quote}
  For most of the theoretical development, it suffices to use the same domain of
  values for all of the attributes. Thus we now fix a countably infinite set
  \textbf{dom} [...].
\end{quote}
So apparently the reals are not a possible choice of domain (because they're
uncountable) and we're not even going to worry about the existence of different
types of value. (This is however consistent with the logical view, as we will
see later.)

For now, though, ignore all this and assume that we have some domains
$\mathscr{D}_i$ without enquiring too much about how big they are. The
definition of a \emph{table} then, is that it is a finite subset of
$\mathscr{D}_i\times \mathscr{D}_j\times\dotsm\times\mathscr{D}_k$ for some $i, j, \dots, k$;
that is, it is a relation.\footnote{Hence the name `relational model.'}

The ensuing story raises at least four kinds of question. What is a table
supposed to mean? What calculations can we effect on tables? What enquiries
might we make of collections of tables? And what other information is supported
by the relational model other than the brute existnce of tables? We start with
the second question.

\subsection{The relational algebra}

Table~\ref{tab:relational-algebra} summarises the operations on relations known
as the `relational algebra.' Since relations are sets, there are set-theoretic
operations (union, intersection, and set difference) as well as `relational'
operations (selection, projection, and join).

\begin{table}[ht]
  \begin{tabular}{cl}
    $A \cup B$ & $A$ and $B$ must be relations over the same domains \\
    $A \cap B$ & $A$ and $B$ must be relations over the same domains \\
    $A \backslash B$ & $A$ and $B$ must be relations over the same domains \\
    

  \end{tabular}
\end{table}



\section{Sets and logic}




intension vs extension












\printbibliography

\end{document}
