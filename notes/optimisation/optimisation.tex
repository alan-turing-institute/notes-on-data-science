\documentclass[10pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{beton}
\usepackage{eulervm}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{microtype}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{color}
% \usepackage[medium, compact]{titlesec}
%\usepackage[inline]{asymptote}
%\usepackage{tikz-cd}
\DeclareFontSeriesDefault[rm]{bf}{sbc}
% \usepackage{amssymb}
%% Turing grid is 21 columns (of 1cm if we are using A4)
%% Usually 4 "big columns", each of 4 text cols plus 1 gutter col;
%% plus an additional gutter on the left.
\usepackage[left=1cm, textwidth=11cm, marginparsep=1cm, marginparwidth=7cm]{geometry}
\usepackage[Ragged, size=footnote, shape=up, alerton]{sidenotesplus}
\definecolor{Red}{rgb}{1,0,0}
%% We used to use a two-column layout
% \setlength{\columnsep}{1cm}
\title{Increasingly tricky optimisation problems}
\author{James Geddes}
\date{\today}
%%
\DeclareBoldMathCommand{\setR}{R}
\DeclareBoldMathCommand{\bfC}{C}
\DeclareBoldMathCommand{\bfG}{\Gamma}
\newcommand{\id}{\mathbold{1}} 
\newcommand{\bzero}{\mathbold{0}} % I don't know why \bm{0} fails.
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\nullspace}{null}
\newcommand{\eg}{\emph{Example:}}
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\isdef}{\mathrel{\stackrel{\text{def}}{=}}}
\hyphenation{anti-sym-met-ric}
%%
\usepackage[backend=biber]{biblatex}
\addbibresource{../references.bib}
\DefineBibliographyStrings{english}{
  andothers = {\mkbibemph{et\addabbrvspace al\adddot}}
}
%%
\begin{document}
\maketitle

We consider a series of increasingly tricky minimisation
problems.\sidenote*{\emph{Exercise:} Find the value of $x$ that
  minimises the function $f(x) = x^2 - 4x + 5$.} 

\section{Functions of a single variable}\label{sec:univariate}
\begin{marginfigure}
  \centering
  \includegraphics{sinxpx2.pdf}
  \margincaption{The function $f(x) = x^2+\sin x$.}\label{fig:sinxpx2}
\end{marginfigure}

Figure~\ref{fig:sinxpx2} is a graph of the function
$f(x) = x^2+\sin x$. By inspection of the graph, one can see that $f$
has a minimum somewhere around $x = 0.5$. The value of $x$ at which
$f$ attains its minimimum is called the \emph{minimiser} of $f$ and
written~$x^*$. For this function the minimiser is $x^* \approx -0.5$. How
might we compute a more accurate value? That is, how might we find
\begin{equation*}
  x^* = \argmin_{x\in\setR} f(x)?
\end{equation*}

At the minimum of a function its derivative is zero. So one approach
to finding the minimum of $f(x)$ is to find the values of $x$ for
which $f'(x)=0$.

\begin{marginfigure}
  \centering \includegraphics{cosxp2x.pdf} \margincaption{One step in
    the iterative approach to finding the zero of a function. Blue
    line: The derivative of the function shown in
    figure~\ref{fig:sinxpx2}: $f'(x) = 2x+\cos x$. Orange line: the
    linear approximation to $f'(x)$ around $x=0$. The point $x_1$ is
    the zero of this linear approximation and will, we hope, be a
    better approximation to the true zero than~$x_0$.}
  \label{fig:cosxp2x}
\end{marginfigure}

The blue line in figure~\ref{fig:cosxp2x} shows the derivative:
$f'(x) = 2x+\cos x$. Although it is clear that this function is indeed
zero near $x\approx-0.5$, the task of finding the \emph{exact} value of the
root does not immediately appear to be any easier than that of finding
the minimum of the original function. There are, to be sure,
\emph{some} functions whose zeros can be found analytically. If
$f'(x)$ had been a \emph{linear} function then finding its root would
have been straightforward. Perhaps we might obtain a guess as to the
zero of $f'(x)$ by replacing $f'(x)$ with an approximating linear
function and then finding the zero of that.

This observation is the basis of the \emph{Newton Raphson}
method. Starting from some initial guess for the minimiser, say
$x_0=0$, we approximate $f'(x)$ near $x=x_0$ by a linear function (the
orange line in figure~\ref{fig:cosxp2x}). We then take, as our next
guess $x_1$, the zero of that function. Continuing in this way, we
construct a new linear approximation to $f'(x)$ around $x=x_1$, find
the zero of that, and so on. For this problem the first few values,
starting from $x=0$, are: $x_0=0$, $x_1=-0.5$, $x_2= -0.450627$, and
$x_3 = -0.450184$. That is already the correct answer to six decimal
places.

How did we compute the linear function that approximates $f'(x)$ at
some $x=\hat{x}$? It is the straight line that is tangent to $f'(x)$
at $\hat{x}$. That is, its value at $\hat{x}$ is $f'(\hat{x})$, and
its slope is the derivative of $f'(x)$ at $\hat{x}$: which is to say,
$f''(\hat{x})$. To write the same thing, the linear function we are
seeking is the function
\begin{equation*}
  f'(\hat{x}) + f''(\hat{x})(x - \hat{x}).
\end{equation*}
The zero of this function is at
\begin{equation}
  x = \hat{x} - \frac{f'(\hat{x})}{f''(\hat{x})},
  \label{eq:linearroot}
\end{equation}
and so the update procedure, from guess $x_i$ to guess $x_{i+1}$, is
\begin{equation}
  x_{i+1} = x_i - \frac{f'(x_i)}{f''(x_i)}.
  \label{eq:newtonraphson}
\end{equation}

\begin{marginfigure}
  \centering
  \includegraphics{sinxpx2-approx.pdf}
  \margincaption{A quadratic approximation to the original function.\label{fig:sinxpx2-approx}}
\end{marginfigure}

There is another way of viewing this iterative procedure. The Newton
Raphson method relies upon the fact that we know how to find the zero
of a linear function. But we already knew how to find the
\emph{minimum} of a \emph{quadratic} function.\sidenote{The minimum of
  $f(x)=\alpha+\beta x + \gamma x^2$ is $x = -\beta/(2\gamma)$, so
  long as $\gamma>0$. (When $\gamma<0$ the function has a maximum, not
  a minimum; when $\gamma=0$ it is a linear function, not a
  quadratic.)} Perhaps we could have approximated the original
function $f(x)$ by a quadratic directly and skipped taking the
derivative?

We now briefly pursue this idea. (See figure~\ref{fig:sinxpx2-approx}
for an illustration.) The approximation method is similar to that of a
linear function. The value of the quadratic, the value of its first
derivative, and the value of its second derivative are set to the
values of the corresponding quantites of the function. (The quadratic
has no higher derivatives.) That is, to approximate $f(x)$ by
$\alpha+\beta x+\gamma x^2$ near to $x=\hat{x}$, set
\begin{equation*}
  \alpha +\beta\hat{x} + \gamma\hat{x}^2 = f(\hat{x});\quad
  \beta +2\gamma\hat{x} = f'(\hat{x});\quad\text{and}\quad
  2\gamma = f''(\hat{x}).
\end{equation*}

The minimum of the quadratic is at $x=-\beta/2\gamma$, which is:
\begin{equation*}
  x = -\frac{\beta}{2\gamma}
  = -\frac{f'(\hat{x})-2\gamma\hat{x}}{2\gamma}
  = -\frac{f'(\hat{x})}{f''(\hat{x})} +\hat{x}. 
\end{equation*}
Perhaps it should not be surprising that this formula is precisely the
same as eq.~\eqref{eq:linearroot}. In particular, we were not, in the
end, able to skip the computation of the second derivative.

\begin{marginfigure}|5ex|
  \begin{equation*}
    x_{i+1} = x_i - \frac{f'(x_i)}{f''(x_i)}.
  \end{equation*}
  \margincaption{Iterative solution to the problem of finding the
    minimiser of $f(x)$ using the Newton Raphson method.}
\end{marginfigure}
There is a lot more to be said about the minimisation of functions of
a single variable. We might ask for the conditions under which
eq.~\eqref{eq:newtonraphson} is guaranteed to converge to the
minimiser. If one is unlucky enough to choose (or arrive at) a place
where the second derivative is zero, then eq.~\eqref{eq:newtonraphson}
will not be applicable. Indeed, there are likely to be numerical
problems merely close to such a place. If the second derivative is
negative, then the iteration step will take the guess towards a local
\emph{maximum} rather than towards a minimum.

There are other approaches to finding the minimum. One might ask why
we don't simply ``follow the gradient of $f(x)$ downhill.'' That would
solve the problem of moving towards a local maximum and would avoid
the computation of the second derivative. This idea is the basis of
\emph{gradient descent}.

\emph{tbd}

Its main difficulty (as I understand it) is that it is necessary to
decide how \emph{far} to follow the gradient downhill on each
iteration. Too small a step and the rate of convergence will be very
slow; too large a step and one risks overshooting the minimum one is
trying to find. In some sense, the right step size should be
determined by how “wiggly” the function is at the current guess. If
the function is very wiggly, one should take small steps to avoid
missing detail in the function. If the function is changing slowly,
there is more license to take a large step. Of course, an obvious
measure of “wiggliness” is the size of the second and higher
derivatives.


\section{Functions on a vector space}
\subsection{What is a ``multivariate function''?}

\sidenote*|-6cm|{\emph{Exercise:} The figure below shows a
  function of two variables, $f(x,y)=1+x+y+x^2+y^2+xy$. For which
  value of the pair $(x,y)$ is $f(x,y)$ a minimum?\sidepar%
    {\centering\includegraphics[width=\marginparwidth]{quadratic.pdf}}\sidepar%
  At the location of a minimum, the derivatives of the function along
  each of the coordinate directions must be zero. These are the
  partial derivatives: the derivative along each coordinate, holding
  the other coordinate constant. For this function, the partial
  derivatives are not hard to compute:
\begin{equation*}
  \frac{\partial f}{\partial x} = 1 + 2x + y;\quad\text{and}\quad
  \frac{\partial f}{\partial y} = 1 + 2y + x.
\end{equation*}
Setting $\partial f/\partial x$ and $\partial f/\partial y$ to zero, we obtain
$x = y = -1/3$.}

% As in the one-dimensional case, the condition that the
% partial derivatives at $(x,y)$ are zero is necessary but not
% sufficient for the existence of a local minimum at~$(x,y$). It is
% therefore necessary to check what kind of extremum one has found: the
% partial derivatives will also be zero at a local maximum, as well as
% at so-called “saddle points” where the function is a local minimum
% along one direction but a local maximum along another direction.

% One might also worry, \emph{a priori}, whether it is necessary to
% check the derivatives along other directions as well as the coordinate
% directions. Even if the partial derivatives along lines of constant
% $x$ and along lines of constant $y$ are zero, is that sufficient to
% say that the derivative in \emph{any} direction is zero? It is common
% practice to simply problems by means of a “change of variables.” One
% attempts to find “new coordinates,” $u(x,y)$ and $v(x,y)$ in the hope
% that when $f$ is expressed in terms of these new variables it will
% present a simpler problem. 

We would now like to generalise the method of
Section~\ref{sec:univariate} to the multi-dimensional case. In order
to do so, we must confront a technical question: what is the domain of
the function whose minimiser we wish to find? In
Section~\ref{sec:univariate} we considered functions
$f\colon\setR\to\setR$; now we are considering functions
$f\colon M\to \setR$, where $M$ is some sort of “space.” But what kind
of space, exactly?

It is common, in machine learning, to say that this space is $\setR^n$
(for some $n$) and strongly to imply that it comes with the natural
vector space stucture on~$\setR^n$. One speaks of a ``vector'' of
parameters, say, or a ``vector'' of observations.\sidenote{There is
  another sense of ``vector,'' which I suspect causes confusion, which
  is the computer scientists' notion of ``a list-like data structure''
  (often with $O(1)$ access time). For that concept, we use the terms
  ``pair,'' (for two) ``triple,'' (for three) and ``tuple'' (in
  general).} \textcite{deisenroth2020mathematics}, for example, say
explicitly at the beginning of section 7.1 (pp.~228) that,
``$f\colon\setR^d\to\setR$ is an objective function that captures the
machine learning problem at hand.''

In point of fact, the spaces that arise in applications are rarely the
vector space $\setR^n$. Indeed, they are rarely a vector space at all;
and even when they are, there is typically no ``canonical basis,''
akin to the canonical basis of~$\setR^n$. In order for $M$ to be a
vector space, it is necessary for there to be a notion of ``linear
combinations'' of elements in~$M$. It is easy to think of examples
where there is no such notion: consider a model, containing a
parameter that is constrained to be strictly positive. One cannot take
arbitrary linear combinations of positive numbers and still produce a
positive number.\sidenote{Of course, one might be able to
  \emph{impose} a vector space structure by \emph{fiat}, as it
  were. For example, one could define the ``sum'' of two non-negative
  parameters, $p$ and $q$, as $pq$. But such an imposition will be
  unnatural: it does not reflect any truth about the situation we are
  attempting to analysis. Relying on any particular, arbitrary
  definition like this is likely to produce a result that
  \emph{depends} upon the particular definition chosen.}

Fortunately, it turns out that, in general, it is not necessary to
have available a notion of ``addition of points'' in~$M$. With one
important caveat, we will be able to get away with thinking of $M$ (or
at least, a region of $M$) as ``rather like'' a region of
$\setR^n$.\sidealert{tbd: I am not entirely sure, anymore, that this
  is true.} That is, we shall imagine there is a coordinate system on
$M$ that allows us to refer to points in $M$ as if they were points
in~$\setR^n$.

The caveat is that all our results ought to be independent of
coordinate system: it should not matter, for the theory, what
particular parametrisation we choose. To reinforce this idea, we shall
typically write points in $M$ as simply $p\in M$, making no reference to
any particular parametrisation. That is, we shall not refer to some
element of $M$ as ``a parameter vector, $\mathbold{p}$,'' because, in
general, $p$ is not a vector.\sidenote{There \emph{is} one important
  application in which $M$ does have a vector-space structure. In a
  regression problen, $M$ is a space of candidate functions and
  $f\colon M\to \setR$ is a ``loss function.'' If $M$ is a vector space,
  the problem is known as \emph{linear} regression. Note that linear
  regression is a special case of regression: that's why it has a
  special name.}

Sometimes, as in the next section, we shall go along with conventional
practice and assume that (at least in the region of some point) $M$
has a vector-space structure. A version of the caveat applies here as
well: any results should be independent of basis. To reinforce
\emph{this} idea, we will typically write a vector space as simply
$V$. Even though $V$ might be isomorphic to some $\setR^n$ we shall
not write it as such because that implies making a choice of a
particular basis.

% (Although, as we shall see, they are often
% ``close enough, in the ways that matter.'') There are two reasons for
% this. First, the space $M$ may not have the topological structure of
% $\setR^n$ ``in the large.'' One might want to find the minimiser of a
% function defined on a sphere,\sidenote{Here is an example of a problem
%   set on a sphere. Let $h(p)$ be the height above sea-level of a
%   point, $p$, on the Earth. Here of course we are modelling the Earth
%   as a sphere,~$S^2$. It seems perfectly reasonable to ask for the
%   maximiser of $h(p)$ (presumably, it is the location of Mt.\ Everest)
%   but $h$ is not a function $h\colon \setR^2\to\setR$, it is a function
%   $h\colon S^2\to\setR$.} but a sphere is not the same as the
% plane. There is no ``reasonable'' coordinate system that works for the
% whole sphere. Second, there is, typically, no notion available of a
% ``linear combination'' of elements of~$M$ and so no vector space
% structure on~$M$.\sidenote{There \emph{is} one important application
%   in which $M$ does have a vector-space structure. In a regression
%   problen, $M$ is a space of candidate functions and
%   $f\colon M\to \setR$ is a ``loss function.''. If the set $M$ is a
%   vector space, the problem is known as \emph{linear} regression. Note
%   that linear regression is a special case of regression: that's why
%   it has a special name.}

% Both of these problems can be solved.

% Roughly speaking, the first problem is solved by restricting attention
% to regions of $M$, ones that are ``large enough'' to cover the
% features of interest but ``small enough'' to ``look like a piece of
% $\setR^n$.'' The solution to the second problem, again very roughly,
% is to observe that we really only use vectors to describe directional
% derivatives; and directional derivatives, it turns out, \emph{do} form
% a vector space.

% The mathematical structure that one needs to implement these ideas is
% that of a \emph{differentiable manifold}. In the following, we will
% not make use of this general notion. Nonetheless, there is a certain
% intuition arising from the subject that one should keep in mind. Here
% is how one should think about things. The concept of a vector space
% clarifies what one means by ``a space like $\setR^n$, only there is no
% preferred basis.'' If, in a particular application, there is no
% preferred basis, then one should avoid writing down expressions that
% make use of one; modelling the domain with a vector space allows one
% to keep straight what depends on a basis and what does not. In a
% similar way, the concept of a differentiable manifold clarifies what
% one means by ``a space like $\setR^n$, only there is no preferred
% coordinate system.'' 

\subsection{Vector derivatives}
\sidenote*{\textbf{Notation.} There is a
  profusion of notation for vectors (see the table). We shall write
  $v^a\in V$ to denote a vector\,---\,an element of some vector
  space,~$V$. Note that we do \emph{not} mean by this notation ``the
  $a$th element of the vector;'' we mean ``the vector itself,'' the
  \emph{Ding an sich}. To write the number that is the component of
  $v^a$ in some (understood) basis, we shall write $v^\mu$, with a Greek
  index. \sidepar The notation we use is known as ``abstract index
  notation'' and is due to Penrose. It has the advantage that it
  extends nicely to other denizens of the vector universe. To For
  example, an element of $\mathcal{L}(V, V)$, an operator, is written
  $T^a{}_b$, with one raised and one lowered index. The action of
  $T^a{}_b$ on some vector $v^a$ is written $T^a{}_b v^b$, which has
  obvious similarities to basis-dependent computation,
  $\sum_\mu T^\mu{}_\nu v^\nu$.}

Let $V$ be a finite-dimensional vector space and $f\colon V\to\setR$ a
real-valued function on~$V$.

We would like to say, as we did in the one-dimensional case, that the
condition for some $p^*\in V$ to be a minimiser of $f$ is that the
``derivative'' of $f$ is zero at~$p^*$. Thus, we must give a meaning,
in the case where $f$ is defined over a vector space, to the notion of
a derivative.
\begin{margintable}
  \centering
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}{@{}l@{\hspace{4pt}}c@{\hspace{3pt}}|@{\hspace{3pt}}c@{\hspace{4pt}}c@{\hspace{4pt}}c@{\hspace{4pt}}c@{\hspace{4pt}}c@{}}
    \toprule
    Concept & & \multicolumn{5}{c}{Alternative notations} \\
    \midrule
    Vector      & $v^a$      & $\mathbold{v}$   & $\vec{v}$
                             & $v$ & $v^i$ & $\lvert v\rangle$ \\
    Dual vector       & $w_a$      & $\mathbold{w}^T$ & $\tilde{w}$
                             & $w$ & $w_j$ & $\langle w\rvert$\\
    Operator    & $T^a{}_b$  & $\mathbold{T}$   & $\overline{T}$
                             & $T$ & $T^i{}_j$ & $T$ \\
  Contraction & $v^a w_a$  & $\mathbold{w}^T\mathbold{v}$ 
                & $\mathbold{v}\cdot\mathbold{w}$ & $w(v)$ & $v^iw_j$ & $\langle
    w \mid v \rangle$ \\   
  \bottomrule
  \end{tabular}
  \caption{Notation for elements of vector spaces and related
    spaces. The notation we will use is shown in the first column and
    is known as ``abstract index notation.''\label{tab:notation}}
\end{margintable}

% The superscript, in this case “$a$,” should be a roman letter towards
% the beginning of the alphabet. Its meaning is simply that $v^a$ is a
% vector; it does \emph{not} denote that $v^a$ is the $a$th component of a
% vector in some basis. The expression $v^b$ is the same
% vector. Similarly, $w_a$, with the index lowered, denotes an element
% of the dual space, $V^*$. This notation, due to Penrose, is known as
% \emph{abstract index notation}.

% There are other ways of notating an element of some vector space (see
% table~\ref{tab:notation} for some example). A typical approach in a
% mathematics text is to write simply $v\in V$, with no adornment of the
% symbol. A physicist might instead decorate the vector, as in
% $\mathbold{v}\in V$, or $\vec{v}\in V$.

% A problem with these other notations is that they do not naturally
% extend to other denizens of the vector universe. For example, if one
% frequently encounters dual vectors, then the mathematician now has to
% remember which symbols are being used for dual vectors, which for
% vectors, and which for ordinary numbers. A physicst, which using a
% distinguishing typography for vectors, typically struggles with things
% other than vectors. For example, a dual vector might be written using
% the cumbersome (and coordinate-dependent) transpose,
% $\mathbold{v}^T$.\sidenote*{What does $\mathbold{v}^T$ mean? It
%   means, “the matrix representation of that dual vector obtained, from
%   the vector $\mathbold{v}$, by means of the isomorphism between $V$
%   and $V^*$ generated by some particular basis that I have in mind.”}
% And of course there are other spaces whose inhabitants are useful: the
% space of linear maps $V\to V$, say, or the space $V\to V^*$ (where
% bilinear forms live). How should these be written?

% Abstract index notation provides a convenient approach to denoting all
% of these objects. Consider, for example, the dual space, $V^*$, which
% is the space of linear maps from $V$ to the reals (or the
% complexes). A mathematician might write, say, $w(v)$ to denote the
% action of $w\in V^*$ on $v\in V$. That is straightforward, yet some things
% are lost. The value $w(v)$ is, by definition, linear in both $w$ and
% $v$ but that linearity is not apparent from the notation. The action
% of $w$ on $v$ can equally well be thought of as the action of $v$ on
% $w$ but that symmetry is not apparent either.

% In abstract index notation, the action of $w_a\in V^*$ on $v^a\in V$ is
% written $w_av^a$. That is, we write the $w_a$ and $v^a$ next to each
% other, as if we were “multiplying” them, and ensure that the
% \emph{same} index is used for both. (The expression $w_av^b$, with two
% different indices, means something else.) Now the linearity and
% symmetry are clearer: although this expression does \emph{not} denote
% an ordinary product of numbers, it looks like one, and therefore looks
% like it ought to distribute over addition, in the sense that
% $w_a(u^a+v^a) = w_au^a + w_av^a$. Which it does.

% We may sometimes have occasion to choose a basis for $V$. In that
% case, we will denote the $\mu$th component of $v^a$ in that basis by
% $v^\mu$. The distinction is that now we have written a greek index. That
% is to say, whereas $v^a$ is a vector, the \emph{Ding an sich}, the
% expression $v^\mu$ denotes a number, one number for each
% basis. Likewise, by $w_\nu$ we will mean the $\nu$th element of the dual
% vector $w_a$ with respect to some basis on $V^*$ (which will almost
% always be dual basis to whatever basis we have chosen for~$V$).

% The following highly convenient fact is one reason that this notation
% is useful: Fix a basis for $V$ and choose, for a basis of $V^*$, the
% dual basis. Then for $v^a\in V$ and $w_b\in V^*$ we have
% $w_av^a = \sum_{\mu=1}^{\dim V} w_\mu v^\mu$.

% \sidenote*{As a matter of history, physicists have typically written
%   vectors using a basis-dependent representation. As it turns out,
%   physical laws involve a lot of terms like $\sum_\mu v^\mu w_\mu$. It was
%   decided that it would make life easier to drop the “$\sum$” and instead
%   follow the convetion that the summation is implied, so long as some
%   index is repeated, once “up” and once “down.” Abstract index
%   notation has the great benefit of looking \emph{just like} the
%   physicists' notation whilst being coordinate-free.}

% What about other objects? It turns out that this notation handles
% those nicely as well, as long as there aren't too many “individual”
% vector spaces around. For example, we denote an element of
% $\mathcal{L}(V,V^*)$ by means of two lowered indices, like so:
% $Q_{ab}$. To act on some $v^a\in V$ we write $Q_{ab}v^b$. Note that
% after we have “paired up” the $b$s, there is only one index left
% “free,” and that index, $a$, is lowered. Our convention is that a
% thing with a lowered index is an element of $V^*$ and that is indeed
% what the action of $Q$ produces.

% There's no \emph{content} to the above; it's just notation, albeit a
% very suggestive one.\sidenote{Although you could make the case that
%   the content of this notation is the existence of the natural
%   isomorphism between $\mathcal{L}(A\otimes B, C)$ and
%   $\mathcal{L}(A, \mathcal{L}(B, C))$}. It is suggestive because, if one chooses a basis
% for $V$ (and the corresponding dual basis for $V^*$), then one obtains
% true formulae on replacing roman superscripts and subscripts by greek
% ones and adding summations where necessary. For example, suppose
% $Q_{\mu\nu}$ is the matrix representation of $Q_{ab}$. Then the
% $\mu$th component of $Q_{ab}v^b$ is precisely $\sum_\nu Q_{\mu\nu}v^\nu$.

% Abstract index notation has some additional advantages when we come to
% take gradients.

The derivative of a function of one variable, $f(x)$, is an answer to
the question, ``how fast does $f$ increase as $x$ increases?'' In the
present case, the rate of change of $f(p)$ at $p$ will, in general,
depend on the direction in which one is “headed away from~$p$,” and so
any straightforward extension of the one-dimensional derivative will
need to specify such a direction. Fortunately, we have a convenient
object with which to capture the idea of a direction, and that is a
vector.

Thus, let $\delta^a$ be a vector. What is the rate of change of $f(p)$ in
the direction of~$\delta^a$? Consider the straight line, passing through
$p$, consisting of the points $p+\lambda\delta^a$ for
$\lambda\in\setR$. (Note: there is a slight inconsistency of notation
here. Both $p$ and $\delta^a$ are elements of $V$\,---\,that is,
vectors\,---\,and so really we should write $p^a$ rather
than~$p$. However, while we are using $p$ to denote a \emph{point} in
$V$, we are using $\delta^a$ to denote a displacement \emph{from} $p$. I
always imagine the $\delta^a$ as having its ``tail'' at $p$ and its
``head'' pointing away from~$p$.)

The line traced out by $p+\lambda\delta^a$ as $\lambda$ varies over numbers is the ray
of all points that lie ``in the direction of $\delta^a$'' from~$p$. The
function $f$ restricted to this line is a function of the single
variable~$\lambda$. We define the derivative of $f$ in the direction
of $\delta^a$ to be th ordinary derivative of $f(p+\lambda\delta^a)$ with respect
to~$\lambda$.

\emph{Definition:} The \textbf{directional derivative of $f$ along
  $\delta^a$}, which we write as $\partial_\delta f$, is defined by\sidenote*{There is
  unfortunately a profusion of notation for the directional
  derivative. As well as $\partial_\delta f$, I have seen
  $\nabla_\delta f$, $D_\delta f$, and $\text{\pounds}_\delta f$. All of these mean the
  same thing\,--\,unless of course they are used to mean different
  things.}
\begin{equation}
\partial_\delta f \isdef \frac{d}{d\lambda} f(x^a+\lambda\delta^a) \quad\text{evaluated at $\lambda = 0$}.
  \label{eq:directional-derivative}
\end{equation}

\sidenote*{\emph{Exercise:} Show that in one dimension
  eq.~\eqref{eq:directional-derivative} reduces to the usual
  derivative, $df/dx$, under the choice $\delta=1$. Hint: Use a change of
  variables, $u = x+\lambda$.}
The directional derivative at $p$ of a function $f$ depends on the
direction,~$\delta^a$, in which the derivative is taken. One might imagine
that the dependence of $\partial_\delta f$ on $\delta^a$ is some terribly complicated
thing, depending in various difficult-to-express ways on the
direction. Remarkably, however, it is not; it is in fact, a linear
map.\sidenote{To see that the directional derivative is linear,
  let $u^a$ and $v^a$ be vectors. We shall show that
  $\partial_{\alpha u+\beta v}f = \alpha\partial_u f+ \beta\partial_v f$. Let
  $\tilde{\alpha}(\lambda)$ and $\tilde{\beta}(\lambda)$ be functions of
  $\lambda$ and consider the derivative, with respect to $\lambda$, of the
  function $f(x^a+\tilde{\alpha}u^a+\tilde{\beta}v^a)$. The chain rule tells
  us:
\begin{equation}
  \frac{df}{d\lambda} = \frac{\partial f}{\partial \tilde{\alpha}} \frac{d\tilde{\alpha}}{d\lambda} +
  \frac{\partial f}{\partial \tilde{\beta}} \frac{d\tilde{\beta}}{d\lambda}
  \label{eq:chain-rule}
\end{equation}
Now, consider the special case of
$\tilde{\alpha}=\alpha\lambda$ and $\tilde{\beta}=\beta\lambda$. On the left-hand side of
eq.~\eqref{eq:chain-rule} we have:
\begin{equation*}
  \frac{df}{d\lambda} = \frac{d}{d\lambda} f\bigl(x^a+\lambda(\alpha u^a +\beta v^a)\bigr), 
\end{equation*}
which, evaluated at $\lambda=0$, is the directional derivative
$\partial_{\alpha u+\beta v} f$.
\sidepar%
To evaluate the right-hand side of eq.~\eqref{eq:chain-rule}, note
that $d\tilde{\alpha}/d\lambda = \alpha$ and
$d\tilde{\beta}d\lambda = \beta$. Furthermore,
$\partial f/\partial \tilde{\alpha}$, evaluated at
$\tilde{\alpha}=\tilde{\beta}=0$ is precisely the directional
derivative~$\partial_u f$. Thus we have,
\begin{equation*}
  \partial_{\alpha u+\beta v} f = \alpha\partial_u f + \beta\partial_v f.
\end{equation*}
In other words, the map $\partial$ is a linear map.}
That is, for given $f$ and $p$, there exists a \emph{dual} vector,
written $\nabla_a f$, having the property that
\begin{equation*}
  (\nabla_a f)\delta^a = \partial_\delta f \quad\text{for all $\delta^a\in V$ (evaluated at $p$)}.
\end{equation*}
The dual vector $\nabla_af$ is known as the \textbf{gradient} of~$f$. It
has a ``down'' index to indicate that it is, in fact, an element
of~$V^*$.

It is a common misconception to imagine that the gradient is a vector,
and that it ``points'' in the direction of greatest increase
in~$f$. But it is, rather, a dual vector and so does not determine a
direction away from~$p$.

\subsection{Minimisation of a function on a vector space}

A necessary condition that $f(p)$ is a minimum at $p^*$ is that its
directional derivative, in any direction, is zero there. That is, for
all $\delta^a$, it must be the case that, evaluated at $p^*$,
$\delta^a(\nabla_a f)=0$. Since this must be true for \emph{every}
$\delta^a$, it follows that a necessary condition for a minimum is
\begin{equation*}
  \nabla_a f = \bzero.
\end{equation*}

Here is a practical example: the multivariate equivalent of the
quadratic. Let $\alpha\in\setR$ be a number; $\beta_a\in V^*$ a dual vector; and
$\Gamma_{ab}$ a symmetric, bilinear form.\sidenote{A bilinear form is an
  element of $\mathcal{L}(V,V^*)$. Equivalently, it is an element
  of~$V^*\otimes V^*$. Equivalently, it is an element of
  $\mathcal{L}(V\otimes V,\setR)$.} We shall attempt to find the minimiser of:
\begin{equation}
  f(v^a) = \alpha + \beta_a v^a + \Gamma_{ab}v^av^b.
\label{eq:quadratic-form}
\end{equation}

To find the minimiser, we seek a point where the directional
derivative is zero in any direction. Let $\delta^a$ be any vector. The
condition for a minimum is
\begin{equation*}
  \partial_\delta f = \partial_\delta\bigl(\alpha + \beta_a v^a + \Gamma_{ab}v^av^b\bigr) = 0.
\end{equation*}
The directional derivative of a sum is the sum of the directional
derivatives (this follows from the corresponding property of the
ordinary derivative). $\partial_\delta \alpha = 0$ because the derivative of a constant
is zero. For the next term, we have
\begin{equation*}
  \partial_\delta (\beta_av^a) = \frac{d}{d\lambda}\biggm|_{\lambda=0}\beta_a(v^a + \lambda \delta^a) = \beta_a\delta^a.
\end{equation*}

Finally, for the bilinear form, we have
\begin{align*}
  \partial_\delta (\Gamma_{ab}v^av^b) &= \frac{d}{d\lambda}\biggm|_{\lambda=0} \Gamma_{ab}(v^a+\lambda\delta^a)(v^b+\lambda\delta^b) \\
  &= \Gamma_{ab}(v^a\delta^b + \delta^av^b) + 2\lambda \Gamma_{ab}\delta^a\delta^b \quad\text{at $\lambda=0$}.
\end{align*}
Evaluating this at $\lambda=0$ gives $\partial_\delta
(\Gamma_{ab}v^av^b)=\Gamma_{ab}(v^a\delta^b+\delta^av^b)$. Since $\Gamma_{ab}$ is symmetric,
this is $2\Gamma_{ab}\delta^av^b$.

Thus, in summary:
\begin{equation*}
  \partial_\delta f(v^a) = \beta_a \delta^a + 2\Gamma_{ab}\delta^av^b =(\beta_a+2\Gamma_{ab}v^b)\delta^a,
\end{equation*}
whence
\begin{equation*}
  \nabla_af = \beta_a+2\Gamma_{ab}v^b.
\end{equation*}

At a minimum, we must have
$\nabla_af = \beta_a+2\Gamma_{ab}v^b = \bzero$. If $\Gamma$ is invertible, so that
$\Gamma^{-1}$ exists, we obtain
\begin{equation*}
  {(p^*)}^a = -\frac{1}{2}{(\Gamma^{-1})}^{ab}\beta_b.
\end{equation*}
(It is also necessary to check that this $p^*$ is a minimum, rather
than a maximum or point of inflection.)

\subsection{Iterative methods}

Now suppose $f\colon V\to\setR$ is a more general function, not
necessarily of the form of eq.~\eqref{eq:quadratic-form}. 

\section{Constrained optimisation}
\begin{marginfigure}
  \centering
  \includegraphics{contour-annotated.pdf}
  \margincaption{Contour plot of two functions, $f$ (in blue) and $g$
    (in orange), on~$\setR^2$. The goal is to find the minimiser of
    $f$ subject to the constraint that $g(x) = 0$ (highlighted).  Note
    that $f$ has a global minimum at $(0,0)$ but that is not on the
    constraint line.  The orange lines show the lines of constant
    $g(x)$, with the ``constraint surface'' $g(x)=0$ (here just a
    line) highlighted. The point $p^*$ is the minimiser of $f$ subject
    to the constraint $g(x)=0$. The vector $\mathbold{v}$ (thought of
    as extending from $p^*$) lies within the constraint surface and
    also has the property that $\partial_\mathbold{v} f = 0$
    at~$p^*$.\label{fig:contour}}
\end{marginfigure}


\section{Linear constraints}


Solve (where $f$ is a quadratic form)
\begin{equation*}
    \label{eq:linear-constraint}
    v^* = \argmin_{v\in W} f(v), 
\end{equation*}
where
\begin{equation*}
    W=\{w^b \in V \mid W^a{}_b w^b = q^a\}
\end{equation*}



Solve
\begin{equation*}
    \label{eq:linear-constraint}
    v^* = \argmin_{v\in W} f(v)
\end{equation*}
where
\begin{equation*}
   W=\{w \in V \mid g(w) = 0\}.
\end{equation*}

We might be tempted to give the condition for a minimum to be
$\nabla_a f=0$, as before. However, that point may occur at a place that
does not lie in~$W$. 


The condition we really want is that $f$ has zero
gradient ``in any direction that lies within~$W$.'' That is, for any
$\delta^a$ which ``points only within $W$,'' we should have
$\partial_\delta f = 0$ at~$v^*$. For $\delta^a$ to ``point within
$W$'' means that $\delta^a$ is tangent to the level surface
$g(w) = 0$; in other words, that $g$ remains constant (namely, zero)
in the direction of~$\delta^a$. In other words, that
$\partial_\delta g = 0$.\sidealert{tbd: This is a convincing argument, but we have
  not shown that the condition that $\partial_\delta f = 0$ at $v^*$ for any
  $\delta^a$ such that $\partial_\delta g = 0$ at $v^*$ implies that
  $f\rvert_W$ is an extremum there.} 

Now suppose $s_a$ and $t_a$ are dual vectors, having the property that
$s_av^a = 0 \implies t_av^a=0$ for all $v^a\in V$. It follows that
$s_a$ and $t_a$ are colinear; that is, that $s_a=\lambda t_a$ for some~$\lambda$. 










% \subsection{A multi-dimensional quadratic}

% Now that we have the appropriate notation we can state the problem of
% this section.

% \emph{Problem:} Fix a finite-dimensional, real vector space,~$V$. Let
% $\alpha\in\setR$ be a number, $w_a\in V^*$ a dual vector, and
% $Q_{ab} \in \mathcal{L}(V,V^*)$ a symmetric, positive-definite, bilinear
% form. Find 
% \begin{equation}
% x^a_\text{min} = \argmin_{x^a\in V} f(x^a),\quad\text{where $f(x^a) = \alpha + w_ax^a + Q_{ab}x^ax^b$}.
% \label{eq:quadr-vect}
% \end{equation}

% In some sense, this is the simplest, non-trivial, function we might
% have attempted to minimise. We can't simplify much futher: a constant
% function attains its minimum everywhere; and a linear function has no
% minimum value.

% Notice that even to say what we mean by a “multidimensional
% quadratric” we had to use the vector space structure of $V$ (in order
% to introduce $w_a$ and $Q_{ab}$).

% \subsection{Solution by completing the square}

% \emph{Solution} (to eq.~\eqref{eq:quadr-vect}):
% \begin{equation}
%   x^a_\text{min} = -\frac{1}{2} {(Q^{-1})}^{ab}w_b.
% \label{eq:sol-quadr-vect}
% \end{equation}

% Before explaining why this is the solution, we describe what it
% means. What is the term ${(Q^{-1})}^{ab}$? Ignoring the indices for a
% minute, it is the inverse of the map $Q$. Since
% $Q\in\mathcal{L}(V, V^*)$, the inverse, $Q^{-1}$, must be an element of
% $\mathcal{L}(V^*, V)$ (that is, it goes the other way). In other words,
% $Q^{-1}$ acts on an element of the dual space, such as $w_a$, to
% produce an element of~$V$. In abstract index notation, that is
% expressed by writing $Q^{-1}$ with two raised indices. To say that
% $Q^{-1}$ is the inverse of $Q$ is to say that
% ${(Q^{-1})}^{ac}Q_{cb} = \id^a{}_b$, where, on the right, $\id^a{}_b$
% is the identity operator on~$V$.

% Why is this the solution? By analogy with the one-dimensional case, we
% might try to “complete the square,” by rewriting $f(x^a)$ as:
% \begin{equation*}
%   f(x^a) = Q_{ab}\Bigl(x^a +
%   \frac{1}{2}{(Q^{-1})}^{ac}w_c\Bigr)\Bigl(x^b +
%   \frac{1}{2}{(Q^{-1})}^{bc}w_c\Bigr) - \frac{1}{4}w_aw_b{(Q^{-1})}^{ab}.
% \end{equation*}
% The right-hand side looks rather complicated. However, the two terms
% in large parentheses are in fact the same vector. That is to say, if
% we set
% \begin{equation*}
%   \xi^a = x^a +  \frac{1}{2}{(Q^{-1})}^{ac}w_c,
% \end{equation*}
% then $f$ becomes the much simpler-looking
% \begin{equation*}
%   f(x^a) = Q_{ab}\xi^a\xi^b + \text{a constant}.
% \end{equation*}
% Now, noting that $Q_{ab}$ is positive-definite\,---\,meaning that
% $Q_{ab}\xi^a\xi^b >0$ unless $\xi^a=\bzero$\,---\,we conclude that the condition
% for $x^a$ to be a minimiser is that $\xi^a = \bzero$ (the zero vector)
% from which eq.~\eqref{eq:sol-quadr-vect} follows.

% Alternatively, we might try taking the derivative again. For that, we
% need to understand how to take derivatives of functions on a vector
% space.





\subsection{Taking the gradient under a choice of basis}

\printbibliography


\end{document}
