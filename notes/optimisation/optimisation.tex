\documentclass[10pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{beton}
\usepackage{eulervm}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{microtype}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{color}
% \usepackage[medium, compact]{titlesec}
%\usepackage[inline]{asymptote}
%\usepackage{tikz-cd}
\DeclareFontSeriesDefault[rm]{bf}{sbc}
% \usepackage{amssymb}
%% Turing grid is 21 columns (of 1cm if we are using A4)
%% Usually 4 "big columns", each of 4 text cols plus 1 gutter col;
%% plus an additional gutter on the left.
\usepackage[left=1cm, textwidth=11cm, marginparsep=1cm, marginparwidth=7cm]{geometry}
\usepackage[Ragged, size=footnote, shape=up]{sidenotesplus}
%% We used to use a two-column layout
% \setlength{\columnsep}{1cm}
\title{Increasingly tricky optimisation problems}
\author{James Geddes}
\date{\today}
%%
\DeclareBoldMathCommand{\setR}{R}
\DeclareBoldMathCommand{\bfC}{C}
\DeclareBoldMathCommand{\bfG}{\Gamma}
\newcommand{\id}{\mathbold{1}} 
\newcommand{\bzero}{\mathbold{0}} % I don't know why \bm{0} fails.
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\nullspace}{null}
\newcommand{\eg}{\emph{Example:}}
\newcommand{\ie}{\emph{i.e.}}
\newcommand{\isdef}{\mathrel{\stackrel{\text{def}}{=}}}
\hyphenation{anti-sym-met-ric}
%%
\usepackage[backend=biber]{biblatex}
\addbibresource{../references.bib}
\DefineBibliographyStrings{english}{
  andothers = {\mkbibemph{et\addabbrvspace al\adddot}}
}
%%
\begin{document}
\maketitle

We consider a series of increasingly tricky minimisation
problems.
\begin{quote}
  \emph{Exercise:} Find the value of $x$ that minimises the function
  $f(x) = x^2 - 4x + 5$.
\end{quote}

\section{Functions of a single variable}\label{sec:univariate}
\begin{marginfigure}
  \centering
  \includegraphics{sinxpx2.pdf}
  \margincaption{The function $f(x) = x^2+\sin x$. What is the value
    of its minimizer?}\label{fig:sinxpx2}
\end{marginfigure}

Figure~\ref{fig:sinxpx2} is a graph of the function
$f(x) = x^2+\sin x$. By inspection of the graph, one can see that $f$
has a minimum. The \emph{minimiser} of $f$\,--\,the value of $x$ at
which $f$ attains its minimum\,--\,is clearly somewhere around
$x \approx -0.5$. How might we compute the actual value? That is, how might
we find
\begin{equation*}
  x_\text{min} = \argmin_{x\in\setR} f(x)?
\end{equation*}

At the minimum of a function its derivative is zero. So one approach
to finding the minimum of $f(x)$ is to find the values of $x$ for
which $f'(x)=0$.

\begin{marginfigure}
  \centering \includegraphics{cosxp2x.pdf} \margincaption{One step in
    the iterative approach to finding the zero of a function. Blue
    line: The derivative of the function shown in
    figure~\ref{fig:sinxpx2}: $f'(x) = 2x+\cos x$. Orange line: the
    linear approximation to $f'(x)$ around $x=0$. The point $x_1$ is
    the zero of this linear approximation and will, we hope, be a
    better approximation to the true zero than~$x_0$.}
  \label{fig:cosxp2x}
\end{marginfigure}

The blue line in figure~\ref{fig:cosxp2x} shows the derivative:
$f'(x) = 2x+\cos x$. Although it is clear that this function is indeed
zero near $x\approx-0.5$, the task of finding the \emph{exact} value of the
root does not immediately appear to be any easier than that of finding
the minimum of the original function. There are, to be sure,
\emph{some} functions whose zeros can be found analytically. If
$f'(x)$ had been a \emph{linear} function then finding its root would
have been straightforward. Perhaps we might obtain a guess as to the
zero of $f'(x)$ by replacing $f'(x)$ with an approximating linear
function and then finding the zero of that.

This observation is the basis of the \emph{Newton Raphson}
method. Starting from some initial guess for the minimiser, say
$x_0=0$, we approximate $f'(x)$ near $x=x_0$ by a linear function (the
orange line in figure~\ref{fig:cosxp2x}). We then take, as our next
guess $x_1$, the zero of that function. Continuing in this way, we
construct a new linear approximation to $f'(x)$ around $x=x_1$, find
the zero of that, and so on. For this problem the first few values,
starting from $x=0$, are: $x_0=0$, $x_1=-0.5$, $x_2= -0.450627$, and
$x_3 = -0.450184$. That is already the correct answer to six decimal
places.

How did we compute the linear function that approximates $f'(x)$ at
some $x=\hat{x}$? It is the straight line that is tangent to $f'(x)$
at $\hat{x}$. That is, its value at $\hat{x}$ is $f'(\hat{x})$, and
its slope is the derivative of $f'(x)$ at $\hat{x}$: which is to say,
$f''(\hat{x})$. To write the same thing, the linear function we are
seeking is the function
\begin{equation*}
  f'(\hat{x}) + f''(\hat{x})(x - \hat{x}).
\end{equation*}
The zero of this function is at
\begin{equation}
  x = \hat{x} - \frac{f'(\hat{x})}{f''(\hat{x})},
  \label{eq:linearroot}
\end{equation}
and so the update procedure, from guess $x_i$ to guess $x_{i+1}$ is
\begin{equation}
  x_{i+1} = x_i - \frac{f'(x_i)}{f''(x_i)}.
  \label{eq:newtonraphson}
\end{equation}

\begin{marginfigure}
  \centering
  \includegraphics{sinxpx2-approx.pdf}
  \margincaption{A quadratic approximation to the original function.\label{fig:sinxpx2-approx}}
\end{marginfigure}

There is another way of viewing this iterative procedure. The Newton
Raphson method relies upon the fact that we know how to find the zero
of a linear function. But we already knew how to find the
\emph{minimum} of a \emph{quadratic} function. Perhaps we could have
approximated the original function $f(x)$ by a quadratic directly and
skipped taking the derivative?

We now briefly pursue this idea. (See figure~\ref{fig:sinxpx2-approx}
for an illustration.) The approximation method is similar to that of a
linear function. The value of the quadratic, the value of its first
derivative, and the value of its second derivative are set to the
values of the corresponding quantites of the function. (The quadratic
has no higher derivatives.) That is, to approximate $f(x)$ by
$\alpha+\beta x+\gamma x^2$ near to $x=\hat{x}$, set
\begin{equation*}
  \alpha +\beta\hat{x} + \gamma\hat{x}^2 = f(\hat{x});\quad
  \beta +2\gamma\hat{x} = f'(\hat{x});\quad\text{and}\quad
  2\gamma = f''(\hat{x}).
\end{equation*}

The minimum of the quadratic is at $x=-\beta/2\gamma$,\sidenote{The minimum of
  $f(x)=\alpha+\beta x + \gamma x^2$ is $x = -\beta/(2\gamma)$, so long as
  $\gamma>0$. (When $\gamma<0$ the function has a maximum, not a minimum; when
  $\gamma=0$ it is a linear function, not a quadratic.)} which is:
\begin{equation*}
  x = -\frac{\beta}{2\gamma}
  = -\frac{f'(\hat{x})-2\gamma\hat{x}}{2\gamma}
  = -\frac{f'(\hat{x})}{f''(\hat{x})} +\hat{x}. 
\end{equation*}
Perhaps it should not be surprising that this formula is precisely the
same as eq.~\eqref{eq:linearroot}. In particular, we were not, in the
end, able to skip the computation of the second derivative.

\begin{marginfigure}|5ex|
  \begin{equation*}
    x_{i+1} = x_i - \frac{f'(x_i)}{f''(x_i)}.
  \end{equation*}
  \margincaption{Iterative solution to the problem of finding the
    minimiser of $f(x)$ using the Newton Raphson method.}
\end{marginfigure}
There is a lot more to be said about the minimisation of functions of
a single variable. We might ask for the conditions under which
eq.~\eqref{eq:newtonraphson} is guaranteed to converge to the
minimiser. If one is unlucky enough to choose (or arrive at) a place
where the second derivative is zero, then eq.~\eqref{eq:newtonraphson}
will not be applicable. Indeed, there are likely to be numerical
problems merely close to such a place. If the second derivative is
negative, then the iteration step will take the guess towards a local
\emph{maximum} rather than towards a minimum.

One might ask why we don't simply ``follow the gradient of $f(x)$
downhill.'' That would solve the problem of moving towards a local
maximum and would avoid the computation of the second derivative. This
idea is the basis of \emph{gradient descent}. Its main difficulty (as
I understand it) is that it is necessary to decide how \emph{far} to
follow the gradient downhill on each iteration. Too small a step and
the rate of convergence will be very slow; too large a step and one
risks overshooting the minimum one is trying to find. In some sense,
the right step size should be determined by how “wiggly” the function
is at the current guess. If the function is very wiggly, one should
take small steps to avoid missing detail in the function. If the
function is changing slowly, there is more license to take a large
step. Of course, an obvious measure of “wiggliness” is the size of the
second and higher derivatives.


\section{Multivariate functions}
\begin{marginfigure}
  \centering \includegraphics{quadratic.pdf}%
  \margincaption{A function of two variables:
    $f(x,y) = 1 + x + y + x^2 + y^2 + xy$.\label{fig:quadratic}}
\end{marginfigure}
\begin{quote}
  \emph{Exercise:} Figure~\ref{fig:quadratic} shows a function of two
  variables, $f(x,y)=1+x+y+x^2+y^2+xy$. For which value of the pair
  $(x,y)$ is $f(x,y)$ a minimum?
\end{quote}
\sidenote*{At the location of a minimum,
  the derivatives of the function along each of the coordinate
  directions must be zero. These are the partial derivatives: the
  derivative along each coordinate, holding the other coordinate
  constant. For this function, the partial derivatives are not hard to
  compute:
\begin{equation*}
  \frac{\partial f}{\partial x} = 1 + 2x + y;\quad\text{and}\quad
  \frac{\partial f}{\partial y} = 1 + 2y + x.
\end{equation*}
Setting $\partial f/\partial x$ and $\partial f/\partial y$ to zero, we obtain
$x = y = -1/3$.}

% As in the one-dimensional case, the condition that the
% partial derivatives at $(x,y)$ are zero is necessary but not
% sufficient for the existence of a local minimum at~$(x,y$). It is
% therefore necessary to check what kind of extremum one has found: the
% partial derivatives will also be zero at a local maximum, as well as
% at so-called “saddle points” where the function is a local minimum
% along one direction but a local maximum along another direction.

% One might also worry, \emph{a priori}, whether it is necessary to
% check the derivatives along other directions as well as the coordinate
% directions. Even if the partial derivatives along lines of constant
% $x$ and along lines of constant $y$ are zero, is that sufficient to
% say that the derivative in \emph{any} direction is zero? It is common
% practice to simply problems by means of a “change of variables.” One
% attempts to find “new coordinates,” $u(x,y)$ and $v(x,y)$ in the hope
% that when $f$ is expressed in terms of these new variables it will
% present a simpler problem. 

We would now like to generalise the method of
Section~\ref{sec:univariate} to the multi-dimensional case. In order
to do so, we must confront a technical question: what is the domain of
the function whose minimiser we wish to find? (We assume that its
codomain is the reals.) In Section~\ref{sec:univariate} we considered
functions $f\colon\setR\to\setR$; now we are considering functions
$f\colon M\to \setR$, where $M$ is some “space.” But what kind of space,
exactly?

It is common, in machine learning, to say that this space is $\setR^n$
(for some $n$) and, in addition, to imply strongly that it comes with
the natural vector space stucture on~$\setR^n$. One speaks of a
``vector'' of parameters, say, or a ``vector'' of
observations. \textcite{deisenroth2020mathematics}, for example, say
explicitly at the beginning of section 7.1 (pp.~228) that,
``$f\colon\setR^d\to\setR$ is an objective function that captures the
machine learning problem at hand.''

In point of fact, the spaces that arise in applications are rarely the
vector space $\setR^n$. (Although, as we shall see, they are often
``close enough, in the ways that matter.'') There are two reasons for
this. First, the space $M$ may not have the topological structure of
$\setR^n$ ``in the large.'' One might want to find the minimiser of a
function defined on a sphere,\sidenote{Here is an example of a problem
  set on a sphere. Let $h(p)$ be the height above sea-level of a
  point, $p$, on the Earth. Here of course we are modelling the Earth
  as a sphere,~$S^2$. It seems perfectly reasonable to ask for the
  maximiser of $h(p)$ (presumably, it is the location of Mt.\ Everest)
  but $h$ is not a function $h\colon \setR^2\to\setR$, it is a function
  $h\colon S^2\to\setR$.} but a sphere is not the same as the
plane. There is no ``reasonable'' coordinate system that works for the
whole sphere. Second, there is, typically, no notion available of a
``linear combination'' of elements of~$M$ and so no vector space
structure on~$M$.\sidenote{There \emph{is} one important application
  in which $M$ does have a vector-space structure and that is linear
  regression. Here $M$ is a space of canidate functions
  $f\colon M\to \setR$ is a ``loss function.''. If the set $M$ is a
  vector space, the problem is known as linear regression. Note that
  linear regression is a special case of regression: that's why it has
  a special name.}

Both of these problems can be solved. Roughly speaking, the first
problem is solved by restricting attention to a region of $M$, one
that is ``large enough'' to cover the features of interest but ``small
enough'' to ``look like a piece of $\setR^n$.'' The solution to the
second problem, again very roughly, is to note that we really only use
vectors to describe directional derivatives; and directional
derivatives, it turns out, 



They are more like vectors in the
computer science sense of a one-dimensional list\,--\,what in
mathematics would be called a ``tuple.''





  
\emph{Problem:} Find the values of $x_1$, $x_2$, \dots, $x_n$ for
which the function $f(x_1, x_2, \dotsc, x_n)$ is
minimised.

In general, this is a much harder problem. To make some progress we
shall make two simplifications. First, we suppose that the function
$f$ is defined not over some arbitrary $n$-dimensional space but over
an $n$-dimensional, real vector space, $V$. That will allow us to make
the second simplification, which is to suppose that $f$ has a
particularly simple form, a multi-dimensional generalisation of the
quadratic from Section~\ref{sec:univariate}.

We digress to introduce some notation.

\subsection{Notation for vectors}

For $V$ a vector space, we write $v^a$ to represent an element of
$V$. \begin{margintable}
  \centering
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}{@{}l@{\hspace{4pt}}c@{\hspace{3pt}}|@{\hspace{3pt}}c@{\hspace{4pt}}c@{\hspace{4pt}}c@{\hspace{4pt}}c@{\hspace{4pt}}c@{}}
    \toprule
    Concept & A.I. & \multicolumn{5}{c}{Alternative notations} \\
    \midrule
    Vector      & $v^a$      & $\mathbold{v}$   & $\vec{v}$
                             & $v$ & $v^i$ & $\lvert v\rangle$ \\
    Dual vector       & $w_a$      & $\mathbold{w}^T$ & $\tilde{w}$
                             & $w$ & $w_j$ & $\langle w\rvert$\\
    Operator    & $T^a{}_b$  & $\mathbold{T}$   & $\overline{T}$
                             & $T$ & $T^i{}_j$ & $T$ \\
  Contraction & $v^a w_a$  & $\mathbold{w}^T\mathbold{v}$ 
                & $\mathbold{v}\cdot\mathbold{w}$ & $w(v)$ & $v^iw_j$ & $\langle
    w \mid v \rangle$ \\   
  \bottomrule
  \end{tabular}
  \caption{Various notations for the objects in vector spaces and
    related spaces. The notation shown in the first column (labelled
    “A.I.”) is “abstract index notation.”\label{tab:notation}}
\end{margintable}

The superscript, in this case “$a$,” should be a roman letter towards
the beginning of the alphabet. Its meaning is simply that $v^a$ is a
vector; it does \emph{not} denote that $v^a$ is the $a$th component of a
vector in some basis. The expression $v^b$ is the same
vector. Similarly, $w_a$, with the index lowered, denotes an element
of the dual space, $V^*$. This notation, due to Penrose, is known as
\emph{abstract index notation}.

There are other ways of notating an element of some vector space (see
table~\ref{tab:notation} for some example). A typical approach in a
mathematics text is to write simply $v\in V$, with no adornment of the
symbol. A physicist might instead decorate the vector, as in
$\mathbold{v}\in V$, or $\vec{v}\in V$.

A problem with these other notations is that they do not naturally
extend to other denizens of the vector universe. For example, if one
frequently encounters dual vectors, then the mathematician now has to
remember which symbols are being used for dual vectors, which for
vectors, and which for ordinary numbers. A physicst, which using a
distinguishing typography for vectors, typically struggles with things
other than vectors. For example, a dual vector might be written using
the cumbersome (and coordinate-dependent) transpose,
$\mathbold{v}^T$.\sidenote*{What does $\mathbold{v}^T$ mean? It
  means, “the matrix representation of that dual vector obtained, from
  the vector $\mathbold{v}$, by means of the isomorphism between $V$
  and $V^*$ generated by some particular basis that I have in mind.”}
And of course there are other spaces whose inhabitants are useful: the
space of linear maps $V\to V$, say, or the space $V\to V^*$ (where
bilinear forms live). How should these be written?

Abstract index notation provides a convenient approach to denoting all
of these objects. Consider, for example, the dual space, $V^*$, which
is the space of linear maps from $V$ to the reals (or the
complexes). A mathematician might write, say, $w(v)$ to denote the
action of $w\in V^*$ on $v\in V$. That is straightforward, yet some things
are lost. The value $w(v)$ is, by definition, linear in both $w$ and
$v$ but that linearity is not apparent from the notation. The action
of $w$ on $v$ can equally well be thought of as the action of $v$ on
$w$ but that symmetry is not apparent either.

In abstract index notation, the action of $w_a\in V^*$ on $v^a\in V$ is
written $w_av^a$. That is, we write the $w_a$ and $v^a$ next to each
other, as if we were “multiplying” them, and ensure that the
\emph{same} index is used for both. (The expression $w_av^b$, with two
different indices, means something else.) Now the linearity and
symmetry are clearer: although this expression does \emph{not} denote
an ordinary product of numbers, it looks like one, and therefore looks
like it ought to distribute over addition, in the sense that
$w_a(u^a+v^a) = w_au^a + w_av^a$. Which it does.

We may sometimes have occasion to choose a basis for $V$. In that
case, we will denote the $\mu$th component of $v^a$ in that basis by
$v^\mu$. The distinction is that now we have written a greek index. That
is to say, whereas $v^a$ is a vector, the \emph{Ding an sich}, the
expression $v^\mu$ denotes a number, one number for each
basis. Likewise, by $w_\nu$ we will mean the $\nu$th element of the dual
vector $w_a$ with respect to some basis on $V^*$ (which will almost
always be dual basis to whatever basis we have chosen for~$V$).

The following highly convenient fact is one reason that this notation
is useful: Fix a basis for $V$ and choose, for a basis of $V^*$, the
dual basis. Then for $v^a\in V$ and $w_b\in V^*$ we have
$w_av^a = \sum_{\mu=1}^{\dim V} w_\mu v^\mu$.

\sidenote*{As a matter of history, physicists have typically written
  vectors using a basis-dependent representation. As it turns out,
  physical laws involve a lot of terms like $\sum_\mu v^\mu w_\mu$. It was
  decided that it would make life easier to drop the “$\sum$” and instead
  follow the convetion that the summation is implied, so long as some
  index is repeated, once “up” and once “down.” Abstract index
  notation has the great benefit of looking \emph{just like} the
  physicists' notation whilst being coordinate-free.}

What about other objects? It turns out that this notation handles
those nicely as well, as long as there aren't too many “individual”
vector spaces around. For example, we denote an element of
$\mathcal{L}(V,V^*)$ by means of two lowered indices, like so:
$Q_{ab}$. To act on some $v^a\in V$ we write $Q_{ab}v^b$. Note that
after we have “paired up” the $b$s, there is only one index left
“free,” and that index, $a$, is lowered. Our convention is that a
thing with a lowered index is an element of $V^*$ and that is indeed
what the action of $Q$ produces.

There's no \emph{content} to the above; it's just notation, albeit a
very suggestive one.\sidenote{Although you could make the case that
  the content of this notation is the existence of the natural
  isomorphism between $\mathcal{L}(A\otimes B, C)$ and
  $\mathcal{L}(A, \mathcal{L}(B, C))$}. It is suggestive because, if one chooses a basis
for $V$ (and the corresponding dual basis for $V^*$), then one obtains
true formulae on replacing roman superscripts and subscripts by greek
ones and adding summations where necessary. For example, suppose
$Q_{\mu\nu}$ is the matrix representation of $Q_{ab}$. Then the
$\mu$th component of $Q_{ab}v^b$ is precisely $\sum_\nu Q_{\mu\nu}v^\nu$.

Abstract index notation has some additional advantages when we come to
take gradients.

\subsection{A multi-dimensional quadratic}

Now that we have the appropriate notation we can state the problem of
this section.

\emph{Problem:} Fix a finite-dimensional, real vector space,~$V$. Let
$\alpha\in\setR$ be a number, $w_a\in V^*$ a dual vector, and
$Q_{ab} \in \mathcal{L}(V,V^*)$ a symmetric, positive-definite, bilinear
form. Find 
\begin{equation}
x^a_\text{min} = \argmin_{x^a\in V} f(x^a),\quad\text{where $f(x^a) = \alpha + w_ax^a + Q_{ab}x^ax^b$}.
\label{eq:quadr-vect}
\end{equation}

In some sense, this is the simplest, non-trivial, function we might
have attempted to minimise. We can't simplify much futher: a constant
function attains its minimum everywhere; and a linear function has no
minimum value.

Notice that even to say what we mean by a “multidimensional
quadratric” we had to use the vector space structure of $V$ (in order
to introduce $w_a$ and $Q_{ab}$).

\subsection{Solution by completing the square}

\emph{Solution} (to eq.~\eqref{eq:quadr-vect}):
\begin{equation}
  x^a_\text{min} = -\frac{1}{2} {(Q^{-1})}^{ab}w_b.
\label{eq:sol-quadr-vect}
\end{equation}

Before explaining why this is the solution, we describe what it
means. What is the term ${(Q^{-1})}^{ab}$? Ignoring the indices for a
minute, it is the inverse of the map $Q$. Since
$Q\in\mathcal{L}(V, V^*)$, the inverse, $Q^{-1}$, must be an element of
$\mathcal{L}(V^*, V)$ (that is, it goes the other way). In other words,
$Q^{-1}$ acts on an element of the dual space, such as $w_a$, to
produce an element of~$V$. In abstract index notation, that is
expressed by writing $Q^{-1}$ with two raised indices. To say that
$Q^{-1}$ is the inverse of $Q$ is to say that
${(Q^{-1})}^{ac}Q_{cb} = \id^a{}_b$, where, on the right, $\id^a{}_b$
is the identity operator on~$V$.

Why is this the solution? By analogy with the one-dimensional case, we
might try to “complete the square,” by rewriting $f(x^a)$ as:
\begin{equation*}
  f(x^a) = Q_{ab}\Bigl(x^a +
  \frac{1}{2}{(Q^{-1})}^{ac}w_c\Bigr)\Bigl(x^b +
  \frac{1}{2}{(Q^{-1})}^{bc}w_c\Bigr) - \frac{1}{4}w_aw_b{(Q^{-1})}^{ab}.
\end{equation*}
The right-hand side looks rather complicated. However, the two terms
in large parentheses are in fact the same vector. That is to say, if
we set
\begin{equation*}
  \xi^a = x^a +  \frac{1}{2}{(Q^{-1})}^{ac}w_c,
\end{equation*}
then $f$ becomes the much simpler-looking
\begin{equation*}
  f(x^a) = Q_{ab}\xi^a\xi^b + \text{a constant}.
\end{equation*}
Now, noting that $Q_{ab}$ is positive-definite\,--\,meaning that
$Q_{ab}\xi^a\xi^b >0$ unless $\xi^a=\bzero$\,--\,we conclude that the condition
for $x^a$ to be a minimiser is that $\xi^a = \bzero$ (the zero vector)
from which eq.~\eqref{eq:sol-quadr-vect} follows.

Alternatively, we might try taking the derivative again. For that, we
need to understand how to take derivatives of functions on a vector
space.

\subsection{Gradients}

The derivative of a function of one variable, $f(x)$, is an answer to
the question, “how fast does $f$ increase as $x$ increases?” We'd like
to ask the same question of a function on a vector space, $f(x^a)$,
where now $x^a\in V$. (Remember that the “$a$” in $x^a$ merely means
that $x^a$ is a vector.)

In contrast to the one-dimensional case, however, the rate of change
of $f$ at $x^a$ will, in general, now depend on the \emph{direction}
in which one is “headed away from~$x^a$,” and so any straightforward
extension of the one-dimensional derivative will need to specify such
a direction.  Fortunately, we have a convenient object with which to
capture the idea of a direction, and that is a vector.

Thus, let $\delta^a$ be a vector. Instead of asking, ``what is the rate of
change of $f(x)$ as $x$ increases?'' we shall ask, ``what is the rate
of change of $f(x^a)$ as $x^a$ changes in the direction
of~$\delta^a$?''\sidenote{Both $x^a$ and $\delta^a$ are elements of
  $V$ but, while we are using $x^a$ to denote a point in $V$, we are
  using $\delta^a$ to denote a displacement from $x^a$. I always imagine
  the $\delta^a$ as having its ``tail'' at $x^a$ and its ``head'' pointing
  away from~$x^a$.} And, in order to capture the idea of ``moving away
from $x^a$ along $\delta^a$,'' we shall introduce a number, $\lambda$, and
consider the point $x^a+\lambda\delta^a$ as $\lambda$ changes. This point has the
property that it is $x^a$ when $\lambda=0$, and ``moves in the direction of
$\delta^a$'' as $\lambda$ increases.

These remarks lead to the following definition.

\emph{Definition:} The \textbf{directional derivative of $f$ along
  $\delta^a$}, which we write as $\partial_\delta f$, is defined by\sidenote*{There is
  unfortunately a profusion of notation for the directional
  derivative. As well as $\partial_\delta f$, I have seen
  $\nabla_\delta f$, $D_\delta f$, and $\text{\pounds}_\delta f$. All of these mean the
  same thing\,--\,unless of course they are used to mean different
  things.}
\begin{equation}
\partial_\delta f \isdef \frac{d}{d\lambda} f(x^a+\lambda\delta^a) \quad\text{evaluated at $\lambda = 0$}.
  \label{eq:directional-derivative}
\end{equation}
\sidenote*{\emph{Exericse:} Show that in one dimension
  eq.~\eqref{eq:directional-derivative} reduces to the usual
  derivative, $df/dx$, under the choice $\delta=1$. Hint: Use a change of
  variables, $u = x+\lambda$.}

The directional derivative of a function $f$ depends on the
direction,~$\delta^a$. Perhaps surprisingly, however, it turns out that
after all it \emph{is} possible to capture a notion of ``the''
derivative of $f$, independent of the direction. The idea is to think
of $\partial_\delta f$ as a function of $\delta^a$: it is this function that is ``the''
derivative. In other words, ``the'' derivative of $f$ at $x^a$ is that
map $\phi\colon \delta^a\to\setR$ defined by
$\phi(\delta^a) = \partial_\delta(f)$ (evaluated at $x^a$).

On the face of it, one might imagine that this $\phi$ is some terribly
complicated thing, depending in various difficult-to-express ways on
its argument,~$\delta^a$. Remarkably, however, it is not; it is in fact, a
linear map.
In other words, there is some dual vector, written
$\nabla_a f$, having the property that
\begin{equation*}
  (\nabla_a f)\delta^a = \partial_\delta f
\end{equation*}
for all vectors $\delta^a\in V$. The dual vector $\nabla_af$ is known as the
\textbf{gradient} of~$f$. It has a ``down'' index to indicate that it
is, in fact, an element of~$V^*$.\sidenote*{To see that the
  directional derivative is linear, let $u^a$ and $v^a$ be vectors. We
  shall show that
  $\partial_{\alpha u+\beta v}f = \alpha\partial_u f+ \beta\partial_v f$. Let
  $\tilde{\alpha}(\lambda)$ and $\tilde{\beta}(\lambda)$ be functions of
  $\lambda$ and consider the derivative, with respect to $\lambda$, of the
  function $f(x^a+\tilde{\alpha}u^a+\tilde{\beta}v^a)$. The chain rule tells
  us:
\begin{equation}
  \frac{df}{d\lambda} = \frac{\partial f}{\partial \tilde{\alpha}} \frac{d\tilde{\alpha}}{d\lambda} +
  \frac{\partial f}{\partial \tilde{\beta}} \frac{d\tilde{\beta}}{d\lambda}
  \label{eq:chain-rule}
\end{equation}
Now, consider the special case of
$\tilde{\alpha}=\alpha\lambda$ and $\tilde{\beta}=\beta\lambda$. On the left-hand side of
eq.~\eqref{eq:chain-rule} we have:
\begin{equation*}
  \frac{df}{d\lambda} = \frac{d}{d\lambda} f\bigl(x^a+\lambda(\alpha u^a +\beta v^a)\bigr), 
\end{equation*}
which, evaluated at $\lambda=0$, is the directional derivative
$\partial_{\alpha u+\beta v} f$.
\sidepar%
To evaluate the right-hand side of eq.~\eqref{eq:chain-rule}, note
that $d\tilde{\alpha}/d\lambda = \alpha$ and
$d\tilde{\beta}d\lambda = \beta$. Furthermore,
$\partial f/\partial \tilde{\alpha}$, evaluated at
$\tilde{\alpha}=\tilde{\beta}=0$ is precisely the directional
derivative~$\partial_u f$. Thus we have,
\begin{equation*}
  \partial_{\alpha u+\beta v} f = \alpha\partial_u f + \beta\partial_v f.
\end{equation*}
In other words, the map $\partial$ is a linear map.}

It is a common misconception to believe that the gradient is a vector,
and that it “points” in the direction of steepest descent. It is
rather a dual vector, not a vector, and so does not determine a
direction away from~$x^a$.

\subsection{Solution by setting the gradient to zero}

A condition that some value of $x^a$ minimises a function is that the
directional derivative of the function is zero at $x^a$ along all
possible directions. That is, for all $\delta^a$, a necessary condition for
a minimum is $\delta^a(\nabla_a f)=0$. Since this must be true for \emph{every}
$\delta^a$, it follows that a necessary condition for a minimum is
\begin{equation*}
  \nabla_a f = \bzero \quad\text{(evaluated at $x^a = x^a_\text{min}$)}.
\end{equation*}

To apply this idea to the original question, we need to compute the
gradient of the function defined in  
eq.~\eqref{eq:quadr-vect}, we need to 


.  Let $\delta^a$ be any vector. Clearly, for
$\alpha$ a constant, $\partial_\delta \alpha=0$. Thus $\nabla_a \alpha=\bzero$.

Let $w_a$ be a dual vector. We have
\begin{equation*}
  \partial_\delta (w_ax^a) = \frac{d}{d\lambda} w_a(x^a + \lambda \delta^a) = w_a\delta^a.
\end{equation*}
Thus $\nabla_a (w_b x^b) = w_a$.

Now let $Q_{ab}$ be a bilinear form. We have
\begin{align*}
  \partial_\delta (Q_{ab}x^ax^b) &= \frac{d}{d\lambda}\bigm|_{\lambda=0} Q_{ab}(x^a+\lambda\delta^a)(x^b+\lambda\delta^b) \\
  &= Q_{ab}(x^a\delta^b + \delta^ax^b) + 2\lambda Q_{ab}\delta^a\delta^b \quad\text{at $\lambda=0$}.
\end{align*}
Evaluating this at $\lambda=0$ gives $\partial_\delta (Q_{ab}x^ax^b)=$




\subsection{Taking the gradient under a choice of basis}

\printbibliography


\end{document}
